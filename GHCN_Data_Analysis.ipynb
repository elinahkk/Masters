{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division,generators\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sci\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "from scipy.stats import norm as scipy_stats_norm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Read the station data downloaded from GHCN archive###\n",
    "Data obtained from http://www.ncdc.noaa.gov/cdo-web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(date_number):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the DATE of GHCN into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(date_number)\n",
    "    return pd.datetime(int(dstring[0:4]),int(dstring[4:6]),int(dstring[6:8]))\n",
    "\n",
    "def get_df(fnm, var, no_missing = True):\n",
    "    \"\"\"\n",
    "    Create a dataframe for a single station, with a time index, for a single\n",
    "    variable of data given as a key word (e.g. PRECIP, TMAX, TMIN).\n",
    "    Requires file path and name (fnm).\n",
    "    no_missing is a Bool that optionally masks out values < -99 from the df.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fnm)\n",
    "    dt_indx = [get_date(date) for date in df.DATE]\n",
    "    data_vals = df[var].values\n",
    "    if var is 'PRCP':\n",
    "        data_vals = data_vals / 10.  # This is to convert precip data to mm\n",
    "    if no_missing:\n",
    "        tmp_df = pd.DataFrame(data=data_vals,\n",
    "                              index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "        mask = tmp_df > -99.  # A catchall value for missing data in GHCN\n",
    "        return tmp_df[mask]\n",
    "    else:\n",
    "        return pd.DataFrame(data=data_vals,\n",
    "                            index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "\n",
    "def get_combined_df(fpth, var):\n",
    "    \"\"\"\n",
    "    From a given file path, and variable, extract data from all .csv files, and\n",
    "    place in a single dataframe object.\n",
    "    \"\"\"\n",
    "    flist = glob.glob(fpth)\n",
    "    df_dic = {}\n",
    "    for f in flist:\n",
    "        df_dic[f[5:]] = get_df(fnm = f, var = var, no_missing=True)\n",
    "    return pd.concat([df_dic[key] for key in df_dic.keys()],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Get_combined() function to create dataframes out of all data in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_tmax = get_combined_df(fpth=\"Data/*.csv\",var=\"TMAX\")\n",
    "df_tmin = get_combined_df(fpth=\"Data/*.csv\",var=\"TMIN\")\n",
    "df_prcp = get_combined_df(fpth=\"Data/*.csv\",var=\"PRCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for station in df_prcp:\n",
    "    print(station, np.max(df_prcp[station]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot time series of precipitation for all stations, and also accumulate the data and plot the average rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of masking and accessing data from stations...\n",
    "#station = df_prcp.keys()[1]\n",
    "#plt.plot(df_prcp[station].index,df_prcp[station],'.',alpha=0.5)\n",
    "#plt.title(\"Station {0:s}\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.KE000063740[df_prcp.KE000063740 > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Time series plots###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Mean and SEM values: Mean uncertainty is given by SEM, where:\n",
    "$SEM = \\frac{\\sigma}{\\sqrt{n-1}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_SEM(data):\n",
    "    \"\"\"\n",
    "    Calculate Standard error of the mean. No nan's \n",
    "    should be in the input (numpy) array.\n",
    "    \"\"\"\n",
    "    return np.std(data)/np.sqrt(len(data) - 1)\n",
    "\n",
    "\n",
    "def gather_daily_stats(date, df):\n",
    "    \"\"\"\n",
    "    For a specified day, given by date, create a short array of \n",
    "    observed values (obs) excluding the NANs. Return the mean, \n",
    "    and SEM value.\n",
    "    Restrictions: more than one observation on a day, not a missing\n",
    "    value, less than 300 mm per day (which is erroneous).\n",
    "    \"\"\"\n",
    "    obs = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "    obs = obs[(obs > -1) & (obs < 500)]\n",
    "    \n",
    "    if len(obs) < 2:\n",
    "        return np.NAN, np.NAN\n",
    "    return np.mean(obs), calc_SEM(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MAD based outlier calculation.\n",
    "#def rej_Olier(data, thresh = 0.):\n",
    "#    \"\"\"\n",
    "#    Calculate biweights of mean to reject outliers in df_prcp. No nan's \n",
    "#    should  also be in the input (numpy) array.\n",
    "#    \"\"\"\n",
    "#    diff = np.abs(data - np.median(data))\n",
    "#    mad = np.median(diff)   #median of the absolute deviation\n",
    "#    mod_obs = diff/mad if mad else 0.\n",
    "#    return data[mod_obs > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an accumulated time series (with SEM uncertainty values)\n",
    "means = []\n",
    "sems = []\n",
    "for day in df_prcp.index:\n",
    "    tmp_mean, tmp_sem = gather_daily_stats(date=day, df=df_prcp)\n",
    "    means.append(tmp_mean)\n",
    "    sems.append(tmp_sem)\n",
    "means = np.array(means)\n",
    "sems = np.array(sems)\n",
    "df_prcp['Accumulated']=pd.Series(means,index=df_prcp.index)  #adding columns to the dataframe!\n",
    "df_prcp['Acc_SEM']=pd.Series(sems,index=df_prcp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_ts = plt.figure(dpi=72)\n",
    "daily_ts.set_size_inches(15,5)      # Specify the figure size\n",
    "ax1 = daily_ts.add_subplot(111)     # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "#ax1.plot(df_prcp.index, df_prcp.Accumulated,'.g',ms=2.0)\n",
    "\n",
    "ax1.errorbar(df_prcp.index, df_prcp.Accumulated,\n",
    "             yerr=df_prcp.Acc_SEM, alpha=0.25, fmt=',')\n",
    "ax1.set_ylim(0,120)\n",
    "plt.xlim('1950-01-01','2015-12-31')\n",
    "plt.title(\"Mean East African Precipitation\")\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.grid(True)\n",
    "plt.show(daily_ts)\n",
    "#daily_ts.savefig('Daily_ts.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Density plots###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N.b. the KDE (kernel density estimate) is Gaussian - which is not true\n",
    "# for precip data (log or power law data)...\n",
    "mask = df_prcp.Accumulated > 0.0\n",
    "daily_dp = plt.figure()\n",
    "daily_dp.set_size_inches(12,5)\n",
    "ax = daily_dp.add_subplot(122)\n",
    "\n",
    "sns.distplot(df_prcp.Accumulated[mask],bins=100,norm_hist = True,kde=False,color = 'r')\n",
    "sns.kdeplot(df_prcp.Accumulated[mask],shade=True,kernel='cos',cumulative=False,color='b')\n",
    "leg1=ax.legend(['KDE','Accumulated mean'],prop={'size':11},\n",
    "                numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_xlim(0,25)\n",
    "ax.set_title(\"East Africa Mean Precipitation\")\n",
    "ax.set_xlabel(r'Precip. (mm day$^{-1}$)')\n",
    "ax.set_ylabel('Density (0-1)')\n",
    "\n",
    "plt.show(daily_dp)\n",
    "#daily_dp.savefig('Densityplot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.Accumulated[df_prcp.Accumulated>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot # Hot tip - look in SEABORN for statistical plots and help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "1. find out why the later part of the data has high variability\n",
    "2. make sure you are happy/add any logical restrictions to improve the data quality in Accumulated dataset\n",
    "3. Caclulate population statistics, histrogram, density plots (PDF, CDF), and fits to the population. Try several fit approaches, and show which is best.\n",
    "4. Use the CDF (or a percentile function) to determine the key (IQR, median, tails etc) of the population\n",
    "5. (hard) try to fit to the population. Reccomend trying a nth order polyfit using np.polyfit()\n",
    "6. Use the statistical threshold values to define 'extreme' precipitation, and work out the:\n",
    "  * frequency of extreme events,\n",
    "  * duration (lenght) of extreme events,\n",
    "  * magnitude (intensity) of extreme events\n",
    "  \n",
    "For task 6, you can plot these statistics as time dependent, or distributions, or something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(df_prcp.Accumulated[mask], bins=60)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram\n",
    "#source code from https://github.com/benlaken/Tanzania/blob/master/Precipitation_Tanzania.ipynb\n",
    "hist_dp = plt.figure()\n",
    "hist_dp.set_size_inches(5,5)          # Specify the output size\n",
    "ax1 = hist_dp.add_subplot(211)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax2 = hist_dp.add_subplot(212)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "# the histogram of the data\n",
    "ax1.set_title(r' Mean East African Precipitation')\n",
    "n, bins, patches = ax1.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled')\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel('Density')\n",
    "n, bins, patches = ax2.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled',cumulative=True)\n",
    "plt.xlabel(r'mm day$^{-1}$')\n",
    "plt.ylabel('Cumulative density')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "#hist_dp.savefig('Density_plots.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   # define extreme quantiles\n",
    "percentileZero    = min(df_prcp.Accumulated[mask])\n",
    "percentileHundred = max(df_prcp.Accumulated[mask])\n",
    "\n",
    "print('Min. precip', percentileZero)\n",
    "print('Max. precip', percentileHundred)\n",
    "print(\"Median\", np.percentile(df_prcp.Accumulated[mask],50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "srtd = sorted(df_prcp.Accumulated[mask])\n",
    "percent = [val/len(srtd) * 100. for val in range(len(srtd))]\n",
    "plt.plot(percent,srtd)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.percentile(df_prcp.Accumulated[mask],90))\n",
    "print(np.percentile(srtd,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. Seasonality###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the DOY mean over the data-period (climatology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doy_mean=[]\n",
    "doy_sem =[]\n",
    "\n",
    "for doy in range(366):\n",
    "    index = df_prcp.index.dayofyear == doy+1 \n",
    "    #print(index)\n",
    "    doy_mean.append(np.nanmean(df_prcp['Accumulated'][index]))\n",
    "    doy_sem.append(calc_SEM(df_prcp['Accumulated'][index]))\n",
    "\n",
    "doy_mean = np.array(doy_mean)\n",
    "doy_sem = np.array(doy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the seasonal climatology East Africa precip data\n",
    "mnths= ['Jan','Feb','Mar','Apr','May','June','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "#mrange = arange(12)\n",
    "\n",
    "my_sclim = plt.figure(dpi=72)\n",
    "my_sclim.set_size_inches(15,6)        # Specify the output size\n",
    "ax1 = my_sclim.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, alpha=0.8)\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"East Africa DOY Mean ($\\mu$) Rainfall\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.grid(True)  \n",
    "#my_sclim.savefig('My_SeasonalClimatology_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly\n",
    "  * Use the seasonal DOY mean to calculate deviations (anomaly) from the daily mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wordy example of how to access/calculate anomaly\n",
    "for daily_rain in zip(df_prcp.index[5000:5003],df_prcp.Accumulated[5000:5003]):\n",
    "    print('Day {0}, rainfall {1:3.2f}mm'.format(daily_rain[0].date(),daily_rain[1]))\n",
    "    print('DOY is',daily_rain[0].dayofyear)\n",
    "    print(\"DOY climo value is {0:3.2f}\".format(doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(\"Daily anomaly is {0:3.2f}\".format(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(np.isnan(daily_rain[1]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Create a seasonal deviation from climatology--\n",
    "#Anomalies = Observation - Climatology\n",
    "prcp_anom = []\n",
    "for daily_rain in zip(df_prcp.index,df_prcp.Accumulated):\n",
    "    if np.isnan(daily_rain[1]):\n",
    "        prcp_anom.append(np.NAN)\n",
    "    else:\n",
    "        prcp_anom.append(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1])\n",
    "prcp_anom = np.array(prcp_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prcp['Acc_anomaly'] = prcp_anom  #adding columns to the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_prcp.index[prcp_anom > -999.],prcp_anom[prcp_anom > -999.],alpha=0.5)\n",
    "#df_prcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---plot the anomalized rainfall data with errors---\n",
    "my_anom = plt.figure(dpi=72)\n",
    "my_anom.set_size_inches(15,6)        # Specify the output size\n",
    "ax1 = my_anom.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(df_prcp['Acc_anomaly'].index,df_prcp['Acc_anomaly'],yerr=df_prcp['Acc_SEM'],xerr=None,alpha=0.5)\n",
    "ax1.set_ylim(-10,100)\n",
    "plt.xlim('1953-01-01','2013-12-31')\n",
    "ax1.set_title(r'Deseasonalized Precipitation ($\\delta$Precip.)')\n",
    "ax1.set_ylabel(r'Anomalized Precip')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "\n",
    "#plt.legend(framealpha=0.9)\n",
    "plt.show(my_anom)\n",
    "#my_anom.savefig('EA anomalized.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doy_values = [doy.dayofyear - 1 for doy in df_prcp.index]\n",
    "figx = plt.figure(dpi=72)\n",
    "figx.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = figx.add_subplot(111)   \n",
    "\n",
    "#---Plot the seasonal climatology East Africa precip data---\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, alpha=0.6, )\n",
    "ax1.plot(df_prcp.index.dayofyear -1 ,df_prcp['Accumulated'],'.',ms=2.5,alpha=1.0,color='r')\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. Extreme Precip Events ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Extreme events have been defined  by absolute threshhold set by SWFDP-RSMC-Nairobi####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extreme rainfall events\n",
    "high_risk = df_prcp.Accumulated[df_prcp.Accumulated > 50]\n",
    "medium_risk = df_prcp.Accumulated[(df_prcp.Accumulated > 30) & (df_prcp.Accumulated < 50)]\n",
    "low_risk = df_prcp.Accumulated[(df_prcp.Accumulated > 20) & (df_prcp.Accumulated < 30)]\n",
    "no_risk = df_prcp.Accumulated[df_prcp.Accumulated < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_floodrisk = plt.figure(dpi=72)\n",
    "daily_floodrisk.set_size_inches(15,5)      # Specify the figure size\n",
    "ax1 = daily_floodrisk.add_subplot(111)     #\n",
    "\n",
    "ax1.plot(high_risk.index, high_risk,'ro',alpha=1.,ms=2)\n",
    "ax1.plot(medium_risk.index, medium_risk,'bo',alpha=0.9,ms=2)\n",
    "ax1.plot(low_risk.index, low_risk,'co',alpha=0.9,ms=2)\n",
    "ax1.plot(no_risk.index, no_risk,'go',alpha=0.9,ms=2)\n",
    "leg1=ax1.legend(['high risk','medium risk','low risk','no risk'],\n",
    "                prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "#plt.xlim('1950-01-01','2015-12-31')\n",
    "plt.title(r\"Mean East African Precipitation\")\n",
    "plt.ylabel(r\"Precipitation (mm day$^{-1}$)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.grid(True)\n",
    "plt.show(daily_floodrisk)\n",
    "\n",
    "#daily_ts.savefig('Daily_floodrisk.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(high_risk.index, df_prcp.index[df_prcp.Accumulated > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency of extreme events\n",
    "floodrisk_freq = []\n",
    "yr_day_count = []\n",
    "years = []\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    tmp_yr_data = df_prcp[\"Accumulated\"][df_prcp.index.year == year]  # pool data for each year\n",
    "    #print(tmp_yr_data)\n",
    "    yr_day_count.append(tmp_yr_data.count())\n",
    "    years.append(year)\n",
    "    if tmp_yr_data.count() > 1:\n",
    "        floodrisk_freq.append(len(tmp_yr_data[no_risk]))\n",
    "        #print(len(tmp_yr_data[no_risk]))\n",
    "    else:\n",
    "        floodrisk_freq.append(np.NAN)   \n",
    "        \n",
    "floodrisk_freq = np.array(floodrisk_freq)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.Accumulated[5000:5005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme events based on statistical values of daily anomalies and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],90)\n",
    "drought_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],10)\n",
    "\n",
    "print('90th percentile = ',flood_threshold)\n",
    "print('10th percentile = ',drought_threshold)\n",
    "print('50th percentile = ',np.percentile(df_prcp['Acc_anomaly'][mask],50))\n",
    "#sns.distplot(df_prcp['Acc_anomaly'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dist = plt.figure()\n",
    "my_dist.set_size_inches(15,5)               # Specify the output size\n",
    "ax1 = my_dist.add_subplot(121)              # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "\n",
    "sns.distplot(df_prcp['Acc_anomaly'][mask],bins=100, norm_hist=True, kde=False) # Filled bars  \n",
    "sns.kdeplot(df_prcp['Acc_anomaly'][mask],shade=False,kernel='gau',cumulative=False,color='r',lw=1.5)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],90), 0.00, 0.2, colors='b',linestyle='--',lw=1.0)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],50), 0.00, 0.2, colors='b',lw=1.0) #Marker line of Median\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],10), 0.00, 0.2, colors='b',linestyle='-.',lw=1.0)\n",
    "leg1=ax1.legend(['KDE','90th percentile','50th percentile','10th percentile','observed anomalies'],\n",
    "                prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel(r'Density',fontsize=11)\n",
    "ax1.set_xlabel('Accumulated precip. anomaly (mm)',fontsize=11)\n",
    "ax1.set_xlim(-10, 40)\n",
    "ax1.set_ylim(0.00, 0.2)\n",
    "\n",
    "\n",
    "plt.show(my_dist)\n",
    "daily_ts.savefig('Daily_ts.pdf',dpi=300)\n",
    "\n",
    "#my_dist.savefig(\"EA_Normalized_Percentile.pdf\",dpi=300,transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mask for the df_prcp to identify the extreme dates (flood and drought)\n",
    "extremes = ((df_prcp['Acc_anomaly'] > flood_threshold) | (df_prcp['Acc_anomaly'] < drought_threshold))\n",
    "flood = (df_prcp['Acc_anomaly'] > flood_threshold)\n",
    "drought = (df_prcp['Acc_anomaly'] < drought_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_threshold = plt.figure(dpi=72)\n",
    "fig_threshold.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = fig_threshold.add_subplot(111)   \n",
    "ax1.scatter(df_prcp['Acc_anomaly'][mask].index, df_prcp['Acc_anomaly'][mask],\n",
    "            alpha=0.1, marker='.')\n",
    "ax1.scatter(df_prcp['Acc_anomaly'][extremes].index, df_prcp['Acc_anomaly'][extremes],\n",
    "            alpha=0.3, marker='.', color='r')\n",
    "plt.title(\"Extreme rainfall based on threshold value detection\")\n",
    "plt.ylabel(\"Precipitation anomaly (mm)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xlim('1953-01-01','1970-12-31')\n",
    "ax1.grid(True)\n",
    "#fig_threshold.savefig('Extreme_Threshhold_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensity, Duration and Frequency of extreme events based on defined statistical extreme threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can use groupby to querey your dataset \n",
    "#pd.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or you can write hacks like this, to pull out data based on the index\n",
    "#---Splitting the data into groups based on extreme threshhold\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    wet_extreme = df_prcp[\"Acc_anomaly\"][flood][df_prcp[\"Acc_anomaly\"][flood].index.year == year]\n",
    "    dry_extreme = df_prcp[\"Acc_anomaly\"][drought][df_prcp[\"Acc_anomaly\"][drought].index.year == year]\n",
    "    \n",
    "    print(year,len(wet_extreme), year,len(dry_extreme))\n",
    "    break \n",
    "# eitherway, do statistics on the frequency, intensity, and duration of flood and drought events\n",
    "# e.g. a time-series. More distributions, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flood_freq = []\n",
    "drought_freq = []\n",
    "yr_day_count = []\n",
    "years = []\n",
    "flood_mean=[]\n",
    "flood_sem =[]\n",
    "drought_mean=[]\n",
    "drought_sem =[]\n",
    "\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    tmp_yr_data = df_prcp[\"Acc_anomaly\"][df_prcp.index.year == year]  # pool data for each year\n",
    "    #print(tmp_yr_data)\n",
    "    yr_day_count.append(tmp_yr_data.count())\n",
    "    years.append(year)\n",
    "    if tmp_yr_data.count() > 1:\n",
    "        flood_freq.append(len(tmp_yr_data[flood]))\n",
    "        #print(len(tmp_yr_data[flood]))\n",
    "        drought_freq.append(len(tmp_yr_data[drought]))\n",
    "        flood_mean.append(np.nanmean(tmp_yr_data[flood]))\n",
    "        flood_sem.append(calc_SEM(tmp_yr_data[flood]))\n",
    "        drought_mean.append(np.nanmean(tmp_yr_data[drought]))\n",
    "        drought_sem.append(calc_SEM(tmp_yr_data[drought]))\n",
    "    else:\n",
    "        flood_freq.append(np.NAN)\n",
    "        drought_freq.append(np.NAN)\n",
    "     \n",
    "        flood_mean.append(np.NAN)\n",
    "        flood_sem.append(np.NAN)\n",
    "        drought_mean.append(np.NAN)\n",
    "        drought_sem.append(np.NAN)\n",
    "        \n",
    "    \n",
    "flood_freq = np.array(flood_freq)\n",
    "drought_freq = np.array(drought_freq)\n",
    "yr_day_count = np.array(yr_day_count)\n",
    "years = np.array(years)\n",
    "flood_mean = np.array(flood_mean)\n",
    "flood_sem = np.array(flood_sem)\n",
    "drought_mean = np.array(drought_mean)\n",
    "drought_sem = np.array(drought_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Intensity\n",
    "my_int = plt.figure(dpi=72)\n",
    "my_int.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = my_int.add_subplot(121)\n",
    "ax2 = my_int.add_subplot(122)\n",
    "\n",
    "ax1.errorbar(years[yr_day_count > 350],flood_mean[yr_day_count > 350],  #Masking missing values\n",
    "             xerr=None, yerr=flood_sem[yr_day_count > 350],color='b', alpha=1.)\n",
    "ax1.set_title('Mean ($\\mu$) intensity of flood events in East Africa\\n based on threshold value detection')\n",
    "ax1.set_ylabel(r'Intensity')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.errorbar(years[yr_day_count > 350],drought_mean[yr_day_count > 350],\n",
    "             xerr=None, yerr=drought_sem[yr_day_count > 350], color='r', alpha=1.)\n",
    "ax2.set_title(' Mean ($\\mu$)intensity of drought events in East Africa\\n based on threshold value detection ')\n",
    "ax2.set_xlabel(r\"Years\")\n",
    "ax2.set_ylabel('Intensity')\n",
    "ax2.grid(True)\n",
    "#my_int.savefig('My_intensity_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency \n",
    "my_ = plt.figure(dpi=72)\n",
    "my_.set_size_inches(15,5)        # Specify the output size\n",
    "ax = my_.add_subplot(121)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax1 = my_.add_subplot(122) \n",
    "\n",
    "ax.plot(years[yr_day_count > 350],flood_freq[yr_day_count > 350], 'bd', alpha=0.8)\n",
    "ax.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350], 'rd',alpha=0.8)\n",
    "leg=ax.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_title('Integer count of Extreme precip events\\n based on threshold value detection')\n",
    "ax.set_ylabel(r'Number of Extreme events (counts)')\n",
    "ax.set_xlabel('Years')\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350]/\n",
    "        yr_day_count[yr_day_count > 350], 'bd', alpha=1.)\n",
    "ax1.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350]/\n",
    "        yr_day_count[yr_day_count > 350],'rd', alpha=1.)\n",
    "leg=ax1.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "#ax.set_ylim(0,100)\n",
    "ax1.set_title('Extreme precip events\\n based on threshold value detection')\n",
    "ax1.set_ylabel(r'Number of Extreme events (counts)')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.show(my_)\n",
    "#my_.savefig('My_Frequency_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration\n",
    "  * If you want to look/do operations on time diffrences, this is called timedelta in the Pandas / datetime packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = tmp_yr_data[drought].index[1] - tmp_yr_data[drought].index[0]\n",
    "print(\"diffrence in days between first and second flood:\",test.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Duration\n",
    "flood_time = []\n",
    "drought_time = []\n",
    "index = []\n",
    "\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    tmp_yr_data = df_prcp[\"Acc_anomaly\"][df_prcp.index.year == year]\n",
    "    index.append(tmp_yr_data.index)\n",
    "    #print(tmp_yr_data.index)\n",
    "    if tmp_yr_data.count() > 1:\n",
    "        count = 1\n",
    "        for n, date in enumerate(tmp_yr_data[flood].index[count - 1:]):\n",
    "            flood_time.append((tmp_yr_data[flood].index[n] - tmp_yr_data[flood].index[n-1]).days)\n",
    "            #print(date.date(), (tmp_yr_data[flood].index[n] - tmp_yr_data[flood].index[n-1]))\n",
    "            #drought_time.append((tmp_yr_data[drought].index[n] - tmp_yr_data[drought].index[n-1]))\n",
    "            \n",
    "    else:\n",
    "        flood_time.append(np.NAN)\n",
    "        #drought_time.append(np.NAN) \n",
    "\n",
    "index = np.array(index)        \n",
    "flood_time = np.array(flood_time)\n",
    "#drought_time = np.array(drought_time)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = flood_time > 0.0\n",
    "#plt.plot(flood_time.index,flood_time[mask],'.r',ms=2.0,alpha=0.75)\n",
    "plt.plot(flood_time[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extreme event based on cumulative statistical values (boxcar approach)####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type of boxcar function\n",
    "test = pd.rolling_sum(df_prcp[\"Accumulated\"], window=2, min_periods=2, center = True)\n",
    "plt.plot(test.index,test,'.r',ms=2.0,alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "for n, date in enumerate(df_prcp.index[window_size - 1:20]):\n",
    "    print(date.date(), (date - df_prcp.index[n -1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df_prcp['Accumulated'][(mask) & (df_prcp['Accumulated'] > 25)].index, \n",
    "         df_prcp['Accumulated'][(mask) & (df_prcp['Accumulated'] > 25)], 'bd', alpha=.5, ms=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corr_matrix = df_prcp\n",
    "#corr_matrix.corr(method='pearson', min_periods=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
