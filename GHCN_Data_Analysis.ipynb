{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Read the station data downloaded from GHCN archive###\n",
    "Data obtained from http://www.ncdc.noaa.gov/cdo-web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(date_number):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the DATE of GHCN into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(date_number)\n",
    "    return pd.datetime(int(dstring[0:4]),int(dstring[4:6]),int(dstring[6:8]))\n",
    "\n",
    "def get_df(fnm, var, no_missing = True):\n",
    "    \"\"\"\n",
    "    Create a dataframe for a single station, with a time index, for a single\n",
    "    variable of data given as a key word (e.g. PRECIP, TMAX, TMIN).\n",
    "    Requires file path and name (fnm).\n",
    "    no_missing is a Bool that optionally masks out values < -99 from the df.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fnm)\n",
    "    dt_indx = [get_date(date) for date in df.DATE]\n",
    "    data_vals = df[var].values\n",
    "    if var is 'PRCP':\n",
    "        data_vals = data_vals / 10.  # This is to convert precip data to mm\n",
    "    if no_missing:\n",
    "        tmp_df = pd.DataFrame(data=data_vals,\n",
    "                              index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "        mask = tmp_df > -99.  # A catchall value for missing data in GHCN\n",
    "        return tmp_df[mask]\n",
    "    else:\n",
    "        return pd.DataFrame(data=data_vals,\n",
    "                            index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "\n",
    "def get_combined_df(fpth, var):\n",
    "    \"\"\"\n",
    "    From a given file path, and variable, extract data from all .csv files, and\n",
    "    place in a single dataframe object.\n",
    "    \"\"\"\n",
    "    flist = glob.glob(fpth)\n",
    "    df_dic = {}\n",
    "    for f in flist:\n",
    "        df_dic[f[5:]] = get_df(fnm = f, var = var, no_missing=True)\n",
    "    return pd.concat([df_dic[key] for key in df_dic.keys()],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Get_combined() function to create dataframes out of all data in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_tmax = get_combined_df(fpth=\"Data/*.csv\",var=\"TMAX\")\n",
    "df_tmin = get_combined_df(fpth=\"Data/*.csv\",var=\"TMIN\")\n",
    "df_prcp = get_combined_df(fpth=\"Data/*.csv\",var=\"PRCP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot time series of precipitation for all stations, and also accumulate the data and plot the average rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of masking and accessing data from stations...\n",
    "#station = df_prcp.keys()[4]\n",
    "#plt.plot(df_prcp[station].index,df_prcp[station],'.',alpha=0.5)\n",
    "#plt.title(\"Station {0:s}\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_prcp.KE000063740['2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prcp.KE000063740[df_prcp.KE000063740 > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Time series plots###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Mean and SEM values: Mean uncertainty is given by SEM, where:\n",
    "SEM=Ïƒn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_SEM(data):\n",
    "    \"\"\"\n",
    "    Calculate Standard error of the mean. No nan's \n",
    "    should be in the input (numpy) array.\n",
    "    \"\"\"\n",
    "    return np.std(data)/np.sqrt(len(data) - 1)\n",
    "\n",
    "\n",
    "def gather_daily_stats(date, df):\n",
    "    \"\"\"\n",
    "    For a specified day, given by date, create a short array of \n",
    "    observed values (obs) excluding the NANs. Return the mean, \n",
    "    and SEM value.\n",
    "    Restrictions: more than one observation on a day, not a missing\n",
    "    value, less than 300 mm per day (which is erroneous).\n",
    "    \"\"\"\n",
    "    obs = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "    obs = obs[(obs > -1) & (obs < 300)]\n",
    "    if len(obs) < 2:\n",
    "        return np.NAN, np.NAN\n",
    "    return np.mean(obs), calc_SEM(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an accumulated time series (with SEM uncertainty values)\n",
    "means = []\n",
    "sems = []\n",
    "for day in df_prcp.index:\n",
    "    tmp_mean, tmp_sem = gather_daily_stats(date=day, df=df_prcp)\n",
    "    means.append(tmp_mean)\n",
    "    sems.append(tmp_sem)\n",
    "means = np.array(means)\n",
    "sems = np.array(sems)\n",
    "df_prcp['Accumulated']=pd.Series(means,index=df_prcp.index)\n",
    "df_prcp['Acc_SEM']=pd.Series(sems,index=df_prcp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_ts = plt.figure(dpi=72)\n",
    "daily_ts.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = daily_ts.add_subplot(111)     # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(df_prcp.index, df_prcp.Accumulated,\n",
    "             yerr=df_prcp.Acc_SEM, alpha=0.75, fmt=',')\n",
    "ax1.set_ylim(0,200)\n",
    "plt.xlim('1950-01-01','2015-08-31')\n",
    "plt.title(\"Mean East African Precipitation\")\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.grid(True)\n",
    "plt.show(daily_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N.b. the KDE (kernel density estimate) is Gaussian - which is not true\n",
    "# for precip data (log or power law data)...\n",
    "mask = df_prcp.Accumulated > 0.0\n",
    "sns.distplot(df_prcp.Accumulated[mask],bins=1000, norm_hist = True,\n",
    "             kde=False,color = 'r')\n",
    "sns.kdeplot(df_prcp.Accumulated[mask],shade=True,kernel='cos',cumulative=False,color='b')\n",
    "plt.xlim(0,25)#max(df_prcp.Accumulated))\n",
    "plt.xlabel('Precip. (mm day$^{-1}$)')\n",
    "plt.ylabel('Density (0-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot # Hot tip - look in SEABORN for statistical plots and help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "1. find out why the later part of the data has high variability\n",
    "2. make sure you are happy/add any logical restrictions to improve the data quality in Accumulated dataset\n",
    "3. Caclulate population statistics, histrogram, density plots (PDF, CDF), and fits to the population. Try several fit approaches, and show which is best.\n",
    "4. Use the CDF (or a percentile function) to determine the key (IQR, median, tails etc) of the population\n",
    "5. (hard) try to fit to the population. Reccomend trying a nth order polyfit using np.polyfit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Seasonality###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the DOY mean over the data-period (climatology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doy_mean=[]\n",
    "doy_sem =[]\n",
    "doy_csum=[]\n",
    "for doy in range(366):\n",
    "    index = df_prcp.index.dayofyear == doy+1 \n",
    "    doy_mean.append(np.nanmean(df_prcp[index]))\n",
    "    doy_sem.append(np.nanstd(df_prcp[index])/np.sqrt(len(df_prcp[index])-1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, alpha=0.6)\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"East Africa DOY Mean ($\\mu$) Rainfall\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the seasonal DOY mean to calculate deviations (anomaly) from the daily mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Anomalies = Observation - Climatology\n",
    "anomalies = []\n",
    "for n,day in enumerate(df_prcp.index):\n",
    "    #print(\"Index: {0} Date: {1} Value: {0:3.3f}\".format(n,df_prcp.index[n].date(),day[0]))\n",
    "    doyi = df_prcp.index[n].dayofyear -1 # Create an index to call doy_mean\n",
    "    #print(n, doy_mean[doyi])\n",
    "    anomalies.append(day - doy_mean[doyi])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = df_prcp\n",
    "corr_matrix.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentile(df, percentile):\n",
    "   # size = len(df_prcp)\n",
    "     \n",
    "    p90 = []\n",
    "    p95 = []\n",
    "    p99 = [] \n",
    "    for day in df_prcp.index:\n",
    "        tmp = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "        p90.append(np.percentile(tmp,90))    # ...find the nth percentile uncertainty values \n",
    "        p95.append(np.percentile(tmp,95)) \n",
    "        p99.append(np.percentile(tmp,99)) \n",
    "        \n",
    "        \n",
    "        return p90, p95, p99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from scipy.stats import scoreatpercentile\n",
    "# percentiles of interest\n",
    "#tmp = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "#perc = [min(tmp), scoreatpercentile(tmp,10), scoreatpercentile(tmp,25),\n",
    "              # scoreatpercentile(tmp,50), scoreatpercentile(tmp,75),\n",
    "               #scoreatpercentile(tmp,90), max(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [154, 400, 1124, 82, 94, 108]\n",
    "print (np.percentile(a,95)) # gives the 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
