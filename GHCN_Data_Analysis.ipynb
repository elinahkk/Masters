{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division,generators\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sci\n",
    "#import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "from scipy.stats import norm as scipy_stats_norm\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the station data downloaded from GHCN archive###\n",
    "Data obtained from http://www.ncdc.noaa.gov/cdo-web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(date_number):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the DATE of GHCN into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(date_number)\n",
    "    return pd.datetime(int(dstring[0:4]),int(dstring[4:6]),int(dstring[6:8]))\n",
    "\n",
    "def get_df(fnm, var, no_missing = True):\n",
    "    \"\"\"\n",
    "    Create a dataframe for a single station, with a time index, for a single\n",
    "    variable of data given as a key word (e.g. PRECIP, TMAX, TMIN).\n",
    "    Requires file path and name (fnm).\n",
    "    no_missing is a Bool that optionally masks out values < -99 from the df.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fnm)\n",
    "    dt_indx = [get_date(date) for date in df.DATE]\n",
    "    data_vals = df[var].values\n",
    "    if var is 'PRCP':\n",
    "        data_vals = data_vals / 10.  # This is to convert precip data to mm\n",
    "    if no_missing:\n",
    "        tmp_df = pd.DataFrame(data=data_vals,\n",
    "                              index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "        mask = tmp_df > -99.  # A catchall value for missing data in GHCN\n",
    "        return tmp_df[mask]\n",
    "    else:\n",
    "        return pd.DataFrame(data=data_vals,\n",
    "                             index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "\n",
    "def get_combined_df(fpth, var):\n",
    "    \"\"\"\n",
    "    From a given file path, and variable, extract data from all .csv files, and\n",
    "    place in a single dataframe object.\n",
    "    \"\"\"\n",
    "    flist = glob.glob(fpth)\n",
    "    df_dic = {}\n",
    "    for f in flist:\n",
    "        df_dic[f[5:]] = get_df(fnm = f, var = var, no_missing=True)\n",
    "    return pd.concat([df_dic[key] for key in df_dic.keys()],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Get_combined() function to create dataframes out of all data in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_tmax = get_combined_df(fpth=\"Data/zone1/*.csv\",var=\"TMAX\")\n",
    "df_tmin = get_combined_df(fpth=\"Data/zone1/*.csv\",var=\"TMIN\")\n",
    "df_prcp = get_combined_df(fpth=\"Data/zone1/*.csv\",var=\"PRCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prcp.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading  the RCA4 - CORDEX data downloaded ICPAC-Kenya data repository ####\n",
    "Data obtained from http://197.254.113.174:8081/repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ERAINT ZONE\n",
    "import netCDF4\n",
    "era = netCDF4.Dataset(\"CORDEX/ECMWF-ERAINT/evaluation/pr30_43_4_13_mean.nc\") #zone 1 model data\n",
    "era2 = netCDF4.Dataset(\"CORDEX/ECMWF-ERAINT/evaluation/pr28_42_-7_4_mean.nc\") #Zone 2 model data\n",
    "eraint = era['pr'][:,0,0]\n",
    "\n",
    "time = era[\"time\"]\n",
    "times = netCDF4.num2date(era['time'][:],units = era['time'].units)\n",
    "times_index = pd.to_datetime(times)\n",
    "#print(times_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating dataframes out of all data in a folder.\n",
    "df_era = pd.DataFrame(data=eraint,index=pd.date_range(start='1980-01-01',end='2010-12-31'),columns=['ERAINT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RX1day: maximum 1-d Precipitation : Highest precipitation amount in 1-d period###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for station in df_prcp:\n",
    "    print(station, np.max(df_prcp[station]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot time series of precipitation for all stations, and also accumulate the data and plot the average rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of masking and accessing data from stations...\n",
    "#station = df_prcp.keys()[1]\n",
    "#plt.plot(df_prcp[station].index,df_prcp[station],'.',alpha=0.5)\n",
    "#plt.title(\"Station {0:s}\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.KE000063619[df_prcp.KE000063619 > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Time series plots###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Mean and SEM values: Mean uncertainty is given by SEM, where:\n",
    "$SEM = \\frac{\\sigma}{\\sqrt{n-1}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_SEM(data):\n",
    "    \"\"\"\n",
    "    Calculate Standard error of the mean. No nan's \n",
    "    should be in the input (numpy) array.\n",
    "    \"\"\"\n",
    "    return np.std(data)/np.sqrt(len(data) - 1)\n",
    "\n",
    "\n",
    "def gather_daily_stats(date, df):\n",
    "    \"\"\"\n",
    "    For a specified day, given by date, create a short array of \n",
    "    observed values (obs) excluding the NANs. Return the mean, \n",
    "    and SEM value.\n",
    "    Restrictions: more than one observation on a day, not a missing\n",
    "    value, less than 200 mm per day (which is erroneous).\n",
    "    \"\"\"\n",
    "    obs = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "    obs = obs[(obs > -1) & (obs < 200)]\n",
    "    \n",
    "    if len(obs) < 2:\n",
    "        return np.NAN, np.NAN\n",
    "    return np.mean(obs), calc_SEM(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MAD based outlier calculation.\n",
    "#def rej_Olier(data, thresh = 0.):\n",
    "#    \"\"\"\n",
    "#    Calculate biweights of mean to reject outliers in df_prcp. No nan's \n",
    "#    should  also be in the input (numpy) array.\n",
    "#    \"\"\"\n",
    "#    diff = np.abs(data - np.median(data))\n",
    "#    mad = np.median(diff)   #median of the absolute deviation\n",
    "#    mod_obs = diff/mad if mad else 0.\n",
    "#    return data[mod_obs > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an accumulated time series (with SEM uncertainty values)\n",
    "means = []\n",
    "sems = []\n",
    "for day in df_prcp.index:\n",
    "    tmp_mean, tmp_sem = gather_daily_stats(date=day, df=df_prcp)#['1961-01-01':'1990-12-31'])\n",
    "    means.append(tmp_mean)\n",
    "    sems.append(tmp_sem)\n",
    "means = np.array(means)\n",
    "sems = np.array(sems)\n",
    "df_prcp['Accumulated']=pd.Series(means,index=df_prcp.index)  #adding columns to the dataframe!\n",
    "df_prcp['Acc_SEM']=pd.Series(sems,index=df_prcp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.max(df_prcp['Accumulated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SEM uncertainty values for ERAINT\n",
    "sems_era = []\n",
    "for day in df_era.index:\n",
    "    tmp_sem = np.std(eraint)/np.sqrt(len(eraint) - 1)\n",
    "    sems_era.append(tmp_sem)\n",
    "sems_era = np.array(sems_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sems_era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts= plt.figure(dpi=300)\n",
    "ts.set_size_inches(15,5)      # Specify the figure size\n",
    "ax1 = ts.add_subplot(111)     # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "#ax1.plot(df_prcp.index, df_prcp.Accumulated,'.g',ms=2.0)\n",
    "\n",
    "ax1.errorbar(df_era.index, eraint,\n",
    "             yerr=sems_era, c='b', alpha=1.,  fmt='-')\n",
    "ax1.set_ylim(0,20)\n",
    "plt.title(\"RCA4 ERAINT (Zone 1) Mean Daily Precipitation\", fontsize=15)\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\", fontsize=15)\n",
    "plt.xlabel(\"Years\", fontsize=15)\n",
    "plt.grid(True)\n",
    "#ts.savefig('Zone1_ERAts.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDII Simple pricipitation intensity index = daily precipitation amount on wet days, w (RR ≥ 1mm) in period ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_ts = plt.figure(dpi=300)\n",
    "daily_ts.set_size_inches(15,5)      # Specify the figure size\n",
    "ax1 = daily_ts.add_subplot(111)     # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(df_prcp.index, df_prcp.Accumulated,\n",
    "             yerr=df_prcp.Acc_SEM, c='b', alpha=1.,lw=1.5, fmt='-')\n",
    "ax1.errorbar(df_era.index, eraint,\n",
    "             yerr=sems_era, c='r', alpha=1., lw=1.5, fmt='-')\n",
    "leg1=ax1.legend(['Station data','RCA4_ERA'],prop={'size':10},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax1.set_ylim(0,200)\n",
    "plt.xlim('1953-01-01','2015-12-31')\n",
    "plt.title(\" East Africa's Zone 2 Daily Average Precipitation\", fontsize=15)\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\", fontsize=15)\n",
    "plt.xlabel(\"Years\", fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show(daily_ts)\n",
    "#daily_ts.savefig('Zone2_ts+ERA.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Density plots###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df_prcp.Accumulated > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N.b. the KDE (kernel density estimate) is Gaussian - which is not true\n",
    "# for precip data (log or power law data)...\n",
    "daily_dp = plt.figure()\n",
    "daily_dp.set_size_inches(12,5)\n",
    "ax = daily_dp.add_subplot(111)\n",
    "\n",
    "sns.distplot(df_prcp.Accumulated[mask],bins=100,norm_hist = True,kde=False,color = 'r')\n",
    "sns.kdeplot(df_prcp.Accumulated[mask],shade=True,kernel='cos',cumulative=False,color='b')\n",
    "leg1=ax.legend(['KDE','Accumulated mean'],prop={'size':11},\n",
    "                numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_title(\"East Africa Mean(Zone1) Precipitation\")\n",
    "ax.set_xlabel(r'Precip. (mm day$^{-1}$)')\n",
    "ax.set_ylabel('Density (0-1)')\n",
    "\n",
    "plt.show(daily_dp)\n",
    "#daily_dp.savefig('Zone1_Densityplot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.Accumulated[df_prcp.Accumulated>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot # Hot tip - look in SEABORN for statistical plots and help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "1. find out why the later part of the data has high variability\n",
    "2. make sure you are happy/add any logical restrictions to improve the data quality in Accumulated dataset\n",
    "3. Caclulate population statistics, histrogram, density plots (PDF, CDF), and fits to the population. Try several fit approaches, and show which is best.\n",
    "4. Use the CDF (or a percentile function) to determine the key (IQR, median, tails etc) of the population\n",
    "5. (hard) try to fit to the population. Reccomend trying a nth order polyfit using np.polyfit()\n",
    "6. Use the statistical threshold values to define 'extreme' precipitation, and work out the:\n",
    "  * frequency of extreme events,\n",
    "  * duration (lenght) of extreme events,\n",
    "  * magnitude (intensity) of extreme events\n",
    "  \n",
    "For task 6, you can plot these statistics as time dependent, or distributions, or something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(df_prcp.Accumulated[mask], bins=60)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram\n",
    "#source code from https://github.com/benlaken/Tanzania/blob/master/Precipitation_Tanzania.ipynb\n",
    "hist_dp = plt.figure()\n",
    "hist_dp.set_size_inches(5,5)          # Specify the output size\n",
    "ax1 = hist_dp.add_subplot(211)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax2 = hist_dp.add_subplot(212)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "# the histogram of the data\n",
    "ax1.set_title(r'PDFs of Daily Precipitation for Zone 2', fontsize=13)\n",
    "n, bins, patches = ax1.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled')\n",
    "n, bins, patches = ax1.hist(eraint, 100, normed=True, facecolor='red', alpha=0.75,\n",
    "                            histtype='stepfilled')\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel('Density', fontsize =15)\n",
    "n, bins, patches = ax2.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled',cumulative=True)\n",
    "n, bins, patches = ax2.hist(eraint, 100, normed=True, facecolor='red', alpha=0.75,\n",
    "                            histtype='stepfilled',cumulative=True)\n",
    "leg1=ax1.legend(['Station data','RCA4_ERA'],prop={'size':10},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "leg1=ax2.legend(['Station data','RCA4_ERA'],prop={'size':10}, numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax1.set_ylim(0,0.5)\n",
    "plt.xlabel(r'mm day$^{-1}$', fontsize=13)\n",
    "plt.ylabel('Cumulative density', fontsize =13)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "#hist_dp.savefig('Zone2_Density_plots.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   # define extreme quantiles\n",
    "percentileZero    = min(df_prcp.Accumulated[mask])\n",
    "percentileHundred = max(df_prcp.Accumulated[mask])\n",
    "\n",
    "print('Min. precip', percentileZero)\n",
    "print('Max. precip', percentileHundred)\n",
    "print(\"Median\", np.percentile(df_prcp.Accumulated[mask],50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "srtd = sorted(df_prcp.Accumulated[mask])\n",
    "percent = [val/len(srtd) * 100. for val in range(len(srtd))]\n",
    "plt.plot(percent,srtd)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.percentile(df_prcp.Accumulated[mask],90))\n",
    "print(np.percentile(srtd,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Seasonality###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the DOY mean over the data-period (climatology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doy_mean=[]\n",
    "doy_sem =[]\n",
    "\n",
    "for doy in range(366):\n",
    "    index = df_prcp['1961-01-01':'1990-12-31'].index.dayofyear == doy+1 \n",
    "    #print(index)\n",
    "    doy_mean.append(np.nanmean(df_prcp['Accumulated']['1961-01-01':'1990-12-31'][index]))\n",
    "    doy_sem.append(calc_SEM(df_prcp['Accumulated']['1961-01-01':'1990-12-31'][index]))\n",
    "\n",
    "doy_mean = np.array(doy_mean)\n",
    "doy_sem = np.array(doy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doy_eramean=[]\n",
    "doy_erasem =[]\n",
    "\n",
    "for doy in range(366):\n",
    "    index = times_index.dayofyear == doy+1 \n",
    "    #print(index)\n",
    "    doy_eramean.append(np.nanmean(eraint[index]))\n",
    "    doy_erasem.append(calc_SEM(eraint[index]))\n",
    "\n",
    "doy_eramean = np.array(doy_eramean)\n",
    "doy_erasem = np.array(doy_erasem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssn_rmean = pd.rolling_mean(doy_mean, window=30, min_periods=0, center = True)\n",
    "ssn_eramean = pd.rolling_mean(doy_eramean, window=30, min_periods=0, center = True)\n",
    "#ssn_rmean[-30:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the seasonal climatology East Africa precip data\n",
    "mnths= ['Jan','Feb','Mar','Apr','May','June','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "#mrange = arange(12)\n",
    "\n",
    "my_sclim = plt.figure(dpi=300)\n",
    "my_sclim.set_size_inches(10,5)        # Specify the output size\n",
    "ax1 = my_sclim.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, c='b', alpha=1., lw=1.5)\n",
    "ax1.errorbar(range(366),doy_eramean,xerr=None, yerr=doy_erasem, c='r', alpha=1.,lw=1.5)\n",
    "#ax1.plot(range(366), ssn_rmean,'b-', alpha=1.0)\n",
    "#ax1.plot(range(366), ssn_eramean,'r-', alpha=1.0)\n",
    "\n",
    "leg1=ax1.legend(['Station data','RCA4_ERA'],prop={'size':12},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"Climatology Precipitation for Zone 2 by Day (& 30day smooth)\", fontsize=15)\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\", fontsize=15)\n",
    "plt.xlabel(\"Day of Year (DOY)\", fontsize=15)\n",
    "plt.grid(True)  \n",
    "my_sclim.savefig('Zone2_SeasonalClimatology_+ERA_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly\n",
    "  * Use the seasonal DOY mean to calculate deviations (anomaly) from the daily mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wordy example of how to access/calculate anomaly\n",
    "for daily_rain in zip(df_prcp.index[5000:5003],df_prcp.Accumulated[5000:5003]):\n",
    "    print('Day {0}, rainfall {1:3.2f}mm'.format(daily_rain[0].date(),daily_rain[1]))\n",
    "    print('DOY is',daily_rain[0].dayofyear)\n",
    "    print(\"DOY climo value is {0:3.2f}\".format(doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(\"Daily anomaly is {0:3.2f}\".format(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(np.isnan(daily_rain[1]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Create a seasonal deviation from climatology--\n",
    "#Anomalies = Observation - Climatology\n",
    "prcp_anom = []\n",
    "for daily_rain in zip(df_prcp.index,df_prcp.Accumulated):\n",
    "    if np.isnan(daily_rain[1]):\n",
    "        prcp_anom.append(np.NAN)\n",
    "    else:\n",
    "        prcp_anom.append(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1])\n",
    "prcp_anom = np.array(prcp_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Create a seasonal deviation from climatology for RCA4\n",
    "era_anom = []\n",
    "for daily_rain in zip(df_era.index,df_era.ERAINT):\n",
    "    if np.isnan(daily_rain[1]):\n",
    "        era_anom.append(np.NAN)\n",
    "    else:\n",
    "        era_anom.append(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1])\n",
    "era_anom = np.array(era_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prcp['Acc_anomaly'] = prcp_anom  #adding columns to the dataframe!\n",
    "df_era['ERA_anomaly'] = era_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_prcp.index[prcp_anom > -999.],prcp_anom[prcp_anom > -999.],alpha=0.5)\n",
    "#df_prcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---plot the anomalized rainfall data with errors---\n",
    "my_anom = plt.figure(dpi=300)\n",
    "my_anom.set_size_inches(10,5)        # Specify the output size\n",
    "ax1 = my_anom.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(df_prcp['Acc_anomaly'].index ,df_prcp['Acc_anomaly'],yerr=df_prcp['Acc_SEM'],\n",
    "             color='b', fmt='.',xerr=None,alpha=0.5)\n",
    "             \n",
    "ax1.errorbar(times_index,era_anom,yerr=sems_era,\n",
    "             color='r', fmt='.',xerr=None,alpha=0.5)\n",
    "ax1.set_ylim(-20,80)\n",
    "#plt.xlim('1953-01-01','1990-12-31')\n",
    "ax1.set_title(r'East Africa (Zone 1) Deseasonalized  Daily Precipitation Climatology ($\\delta$Precip.)')\n",
    "ax1.set_ylabel(r'mm day$^{-1}$')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "plt.show(my_anom)\n",
    "#my_anom.savefig('EA Zone1 Deseasonalized Precip.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doy_values = [doy.dayofyear - 1 for doy in df_prcp.index]\n",
    "figx = plt.figure(dpi=72)\n",
    "figx.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = figx.add_subplot(111)   \n",
    "\n",
    "#---Plot the seasonal climatology East Africa precip data---\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, color='b', alpha=0.8 )\n",
    "ax1.errorbar(range(366),doy_eramean,xerr=None, yerr=doy_erasem, color='k', alpha=0.8 )\n",
    "ax1.plot(df_prcp.index.dayofyear -1 ,df_prcp['Accumulated'],'.',ms=2.5,alpha=1.0,color='r')\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extreme Precip Events ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme events have been defined  by absolute threshhold set by SWFDP-RSMC-Nairobi (Rnn mm = Count of days where RR ≥ user-defined threshold in mm)###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A mask for the df_prcp to identify categories of Extreme rainfall events\n",
    "\"\"\"\n",
    "The thresholds used in here are based on the definitions as used\n",
    "by SWFDP-EA. It should be noted that this hold under natural conditions\n",
    "No risk  - <5mm\n",
    "Low risk - 5mm-20mm\n",
    "Medium risk 20 - 50mm\n",
    "High risk >=50mm\n",
    "\"\"\"\n",
    "cond1 = df_prcp.Accumulated < 5\n",
    "cond2 = df_prcp.Accumulated > 5\n",
    "cond3 = df_prcp.Accumulated < 20\n",
    "highmed_risk = df_prcp.Accumulated[df_prcp.Accumulated > 20] #Medium to high risk\n",
    "high_risk = df_prcp.Accumulated[df_prcp.Accumulated > 50]\n",
    "medium_risk = df_prcp.Accumulated[(df_prcp.Accumulated > 20) & (df_prcp.Accumulated < 50)]\n",
    "low_risk = df_prcp.Accumulated[cond2 & cond3]\n",
    "no_risk = df_prcp.Accumulated[cond1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A mask for the df_era to identify if there are similar Extreme rainfall events in RCA4 data\n",
    "nrisk= df_era.ERAINT[df_era.ERAINT < 5]\n",
    "yrisk = df_era.ERAINT[(df_era.ERAINT>5) & (df_era.ERAINT<20) ]\n",
    "print(len(yrisk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_floodrisk = plt.figure(dpi=72)\n",
    "daily_floodrisk.set_size_inches(12,7)      # Specify the figure size\n",
    "ax1 = daily_floodrisk.add_subplot(111)     #\n",
    "\n",
    "ax1.plot(high_risk.index, high_risk,'ro',alpha=1.,linewidth = 3, ms=3)\n",
    "ax1.plot(medium_risk.index, medium_risk,'bo',alpha=0.9,ms=3)\n",
    "ax1.plot(low_risk.index, low_risk,'co',alpha=0.9,ms=3)\n",
    "ax1.plot(no_risk.index, no_risk,'go',alpha=0.9,ms=3)\n",
    "leg1=ax1.legend(['high risk','medium risk','low risk','no risk'],\n",
    "                prop={'size':12},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "plt.xlim('1953-01-01','1990-12-31')\n",
    "plt.title(r\" Zone 1 Extreme Precipitation Events based on Absolute Threshhold\", fontsize=12)\n",
    "plt.ylabel(r\"Amounts (mm day$^{-1}$)\", fontsize=12)\n",
    "plt.xlabel(\"Years\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show(daily_floodrisk)\n",
    "#daily_floodrisk.savefig('Zone1_ExtremeEvent.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics####\n",
    "###### Frequency of extreme events based on absolute threshhold set by SWFDP-RSMC-Nairobi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#low_risk.groupby( [low_risk.index.year, low_risk.index.month, low_risk.index.day] ).count()\n",
    "lwrisk_freq = low_risk.groupby(low_risk.index.year).count()/365 #To get normalized freq per annum\n",
    "mdrisk_freq = medium_risk.groupby(medium_risk.index.year).count()/365\n",
    "mdhgrisk_freq = highmed_risk.groupby(highmed_risk.index.year).count()/365\n",
    "hgrisk_freq = high_risk.groupby( high_risk.index.year ).count()\n",
    "#print(hgrisk_freq)\n",
    "#ERA\n",
    "yrisk_freq = yrisk.groupby(yrisk.index.year).count()/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frq_rmean_low = pd.rolling_mean(lwrisk_freq, window=10, min_periods=0, center = True)\n",
    "frq_rmean_med = pd.rolling_mean(mdrisk_freq, window=10, min_periods=0, center = True)\n",
    "frq_rmean_medhig = pd.rolling_mean(mdhgrisk_freq, window=10, min_periods=0, center = True)\n",
    "frq_rmean_hig = pd.rolling_mean(hgrisk_freq, window=10, min_periods=0, center = True)\n",
    "\n",
    "#ERA\n",
    "frq_rmean_yrisk = pd.rolling_mean(yrisk_freq, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Frequency plot \n",
    "freq = plt.figure(dpi=300)\n",
    "freq.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = freq.add_subplot(121)\n",
    "ax2 = freq.add_subplot(122)\n",
    "\n",
    "ax1.plot(lwrisk_freq.index, lwrisk_freq ,'b-',ms=10.0,alpha=1., lw=1.5)\n",
    "ax1.plot(yrisk_freq.index, yrisk_freq ,'g-',ms=3.0,alpha=1., lw=1.5)\n",
    "ax1.plot(lwrisk_freq.index, frq_rmean_low,'r--', linewidth=2, alpha=1.)\n",
    "ax1.plot(yrisk_freq.index, frq_rmean_yrisk,'r--', linewidth=2, alpha=1.)\n",
    "ax1.set_title('Zone 2 Frequency of Low risk extreme precip \\n based on Absolute Threshhold')\n",
    "ax1.set_ylabel(r' Normalized counts of low risk events', fontsize = 12)\n",
    "ax1.set_xlabel(r'Years', fontsize = 12)\n",
    "#ax1.set_xlim(1953, 1990)\n",
    "leg1=ax1.legend(['Station data','RCA4_ERA'],prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(mdhgrisk_freq.index, mdhgrisk_freq ,'b-',ms=5.0,alpha=1.,lw=1.5)\n",
    "ax2.plot(mdhgrisk_freq.index, frq_rmean_medhig,'r--', linewidth=2, alpha=1.,lw=1.5)\n",
    "ax2.set_title('Zone 2 Frequency of Medium-High risk extreme precip \\n based on Absolute Threshhold')\n",
    "ax2.set_xlabel(r\"Years\", fontsize = 12)\n",
    "#ax2.set_xlim(1953, 1990)\n",
    "ax2.set_ylabel('Normalized counts of medium risk events', fontsize = 12)\n",
    "ax2.grid(True)\n",
    "\n",
    "#freq.savefig('Zone2_freq_plot+ERA.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration of extreme events####\n",
    "Here I calculate the time between heavy precipitation (risk) from the observed time directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_risk.index[2], low_risk.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = low_risk.index[2] - low_risk.index[1]\n",
    "print(\"diffrence in days between first and second lowrisk:\",test.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowrisk_times = 1\n",
    "for n, date in enumerate(low_risk.index[lowrisk_times - 1:3]):\n",
    "    print(date.date(), (date - low_risk.index[n -1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Duration\n",
    "lowrisk_dur = []\n",
    "mediumrisk_dur = []\n",
    "risk_time = 1\n",
    "for n, date in enumerate(low_risk.index[risk_time - 1:]):\n",
    "    lowrisk_d = (date - low_risk.index[n -1]).days\n",
    "    \n",
    "    lowrisk_dur.append(lowrisk_d)\n",
    "    \n",
    "lowrisk_dur=np.array(lowrisk_dur)    \n",
    "for n, date in enumerate(highmed_risk.index[risk_time - 1:]):    \n",
    "    mediumrisk_d = (date - highmed_risk.index[n -1]).days\n",
    "    \n",
    "    mediumrisk_dur.append(mediumrisk_d)\n",
    "    \n",
    "mediumrisk_dur=np.array(mediumrisk_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Duration plot \n",
    "freq = plt.figure(dpi=72)\n",
    "freq.set_size_inches(20,5)        # Specify the output size\n",
    "ax1 = freq.add_subplot(121)\n",
    "ax2 = freq.add_subplot(122)\n",
    "\n",
    "ax1.plot(low_risk.index, lowrisk_dur ,'b-',ms=2.0,alpha=1.)\n",
    "ax1.set_title('Zone 2 Duration of consecutive Low risk precip \\n events based on absolute threshhold', fontsize=15)\n",
    "ax1.set_ylabel(r'Days between low risk events',fontsize = 14)\n",
    "ax1.set_xlabel(r'Years',fontsize = 14)\n",
    "#ax1.set_xlim('1953-01-03','1990-12-31')\n",
    "ax1.set_ylim(0,200)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(highmed_risk.index, mediumrisk_dur,'b-',ms=3.0,alpha=1.)\n",
    "ax2.set_title(' Zone 2 Duration of consecutive Medium-High risk precip \\n based on absolute threshhold',fontsize=15)\n",
    "ax2.set_ylabel('Days between Medium-High risk events', fontsize = 14)\n",
    "ax2.set_ylim(0,1500)\n",
    "ax2.set_xlabel(r\"Years\", fontsize = 14)\n",
    "#ax2.set_xlim('1953-01-03','1990-12-31')\n",
    "ax2.grid(True)\n",
    "#freq.savefig('Zone2_Duration_Swfdp1.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme events based on statistical values of daily anomalies and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],90)\n",
    "drought_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],10)\n",
    "\n",
    "print('90th percentile = ',flood_threshold)\n",
    "print('10th percentile = ',drought_threshold)\n",
    "print('50th percentile = ',np.percentile(df_prcp['Acc_anomaly'][mask],50))\n",
    "print('99th percentile = ',np.percentile(df_prcp['Acc_anomaly'][mask],99))\n",
    "#sns.distplot(df_prcp['Acc_anomaly'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_era = np.percentile(df_era['ERA_anomaly'],90)\n",
    "drought_era = np.percentile(df_era['ERA_anomaly'],10)\n",
    "\n",
    "print('90th percentile = ',flood_era)\n",
    "print('10th percentile = ',drought_era)\n",
    "print('50th percentile = ',np.percentile(df_era['ERA_anomaly'],50))\n",
    "print('99th percentile = ',np.percentile(df_era['ERA_anomaly'],99))\n",
    "#sns.distplot(df_prcp['Acc_anomaly'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dist = plt.figure()\n",
    "my_dist.set_size_inches(10,5)               # Specify the output size\n",
    "ax1 = my_dist.add_subplot(111)              # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "#Univeriate distribution of Observed daily precipitation.\n",
    "sns.distplot(df_prcp['Acc_anomaly'][mask],bins=100, norm_hist=True, kde=False) # Filled bars  \n",
    "sns.kdeplot(df_prcp['Acc_anomaly'][mask],shade=False,kernel='gau',cumulative=False,color='k',lw=3)\n",
    "sns.distplot(era_anom,bins=100, norm_hist=True, kde=False) # Filled bars  \n",
    "sns.kdeplot(era_anom,shade=False,kernel='gau',cumulative=False,color='r',lw=2)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],90), 0.00, 0.25, colors='b',linestyle='--',lw=2.0)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],50), 0.00, 0.25, colors='b',lw=2.0) #Marker line of Median\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],10), 0.00, 0.25, colors='b',linestyle='-.',lw=3.0)\n",
    "leg1=ax1.legend(['Station data KDE','90th percentile','50th percentile','10th percentile','observed anomalies'],\n",
    "                prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax1.vlines(np.percentile(df_era['ERA_anomaly'],90), 0.00, 0.40, colors='y',linestyle='-',lw=1.5)\n",
    "ax1.vlines(np.percentile(df_era['ERA_anomaly'],50), 0.00, 0.40, colors='y',lw=1.5) #Marker line of Median\n",
    "ax1.vlines(np.percentile(df_era['ERA_anomaly'],10), 0.00, 0.40, colors='y',linestyle='-',lw=1.5)\n",
    "ax1.set_title(r'Zone 1 Normalized Extreme Precipitation Percentile plot', fontsize=15)\n",
    "ax1.set_ylabel(r' Probability Density',fontsize=15)\n",
    "ax1.set_xlabel(r'Anomalies(mm)',fontsize=15)\n",
    "ax1.set_xlim(-10, 20)\n",
    "ax1.set_ylim(0.00, 0.40)\n",
    "ax1.grid(True)\n",
    "my_dist.text(0.71, 0.64, \" __ RCA4 KDE\" ,fontsize=10,color='r')\n",
    "plt.show(my_dist)\n",
    "\n",
    "#my_dist.savefig(\"Zone1_Normalized_Percentile.pdf\",dpi=300)#transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mask for the df_prcp to identify the extreme dates (flood and drought)\n",
    "extremes = ((df_prcp['Acc_anomaly'] > flood_threshold) | (df_prcp['Acc_anomaly'] < drought_threshold))\n",
    "flood = (df_prcp['Acc_anomaly'] > flood_threshold)\n",
    "drought = (df_prcp['Acc_anomaly'] < drought_threshold)\n",
    "wet_xtrm = (df_era['ERA_anomaly']> flood_era)\n",
    "dry_xtrm = (df_era['ERA_anomaly'] < drought_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_threshold = plt.figure(dpi=72)\n",
    "fig_threshold.set_size_inches(8,5)      # Specify the figure size\n",
    "ax1 = fig_threshold.add_subplot(111)   \n",
    "ax1.scatter(df_prcp['Acc_anomaly'][mask].index, df_prcp['Acc_anomaly'][mask],\n",
    "            alpha=0.1, marker='.')\n",
    "ax1.scatter(df_prcp['Acc_anomaly'][extremes].index, df_prcp['Acc_anomaly'][extremes],\n",
    "            alpha=0.8, marker='.', color='r')\n",
    "plt.title(\"Extreme rainfall based on statistical values of daily anomalies and percentiles\")\n",
    "plt.ylabel(\"Precipitation anomaly (mm)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xlim('1953-01-01','1990-12-31')\n",
    "#plt.ylim(-10,70)\n",
    "ax1.grid(True)\n",
    "#fig_threshold.savefig('Zone1 Extreme_Threshhold_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics####\n",
    "#### Intensity, Duration and Frequency (IDF) of extreme events based on defined statistical extreme threshold####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groupby  can be used to querey the dataset \n",
    "#pd.groupby?\n",
    "#OR can write hacks like this, to pull out data based on the index\n",
    "#---Splitting the data into groups based on extreme threshhold\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    wet_extreme = df_prcp[\"Acc_anomaly\"][flood][df_prcp[\"Acc_anomaly\"][flood].index.year == year]\n",
    "    dry_extreme = df_prcp[\"Acc_anomaly\"][drought][df_prcp[\"Acc_anomaly\"][drought].index.year == year]\n",
    "    \n",
    "    print(year,len(wet_extreme), year,len(dry_extreme))\n",
    "    break \n",
    "# eitherway, do statistics on the frequency, intensity, and duration of flood and drought events\n",
    "# e.g. a time-series. More distributions, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For station dataset\n",
    "flood_freq = []\n",
    "drought_freq = []\n",
    "yr_day_count = []\n",
    "years = []\n",
    "flood_mean=[]\n",
    "flood_sem =[]\n",
    "drought_mean=[]\n",
    "drought_sem =[]\n",
    "\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    tmp_yr_data = df_prcp[\"Acc_anomaly\"][df_prcp.index.year == year]  # pool data for each year\n",
    "    #print(tmp_yr_data)\n",
    "    yr_day_count.append(tmp_yr_data.count())\n",
    "    years.append(year)\n",
    "    if tmp_yr_data.count() > 1:\n",
    "        flood_freq.append(len(tmp_yr_data[flood]))\n",
    "        #print(tmp_yr_data[flood])\n",
    "        drought_freq.append(len(tmp_yr_data[drought]))\n",
    "        flood_mean.append(np.nanmean(tmp_yr_data[flood]))\n",
    "        flood_sem.append(calc_SEM(tmp_yr_data[flood]))\n",
    "        drought_mean.append(np.nanmean(tmp_yr_data[drought]))\n",
    "        drought_sem.append(calc_SEM(tmp_yr_data[drought]))\n",
    "    else:\n",
    "        flood_freq.append(np.NAN)\n",
    "        drought_freq.append(np.NAN)\n",
    "     \n",
    "        flood_mean.append(np.NAN)\n",
    "        flood_sem.append(np.NAN)\n",
    "        drought_mean.append(np.NAN)\n",
    "        drought_sem.append(np.NAN)\n",
    "        \n",
    "    \n",
    "flood_freq = np.array(flood_freq)\n",
    "drought_freq = np.array(drought_freq)\n",
    "yr_day_count = np.array(yr_day_count)\n",
    "years = np.array(years)\n",
    "flood_mean = np.array(flood_mean)\n",
    "flood_sem = np.array(flood_sem)\n",
    "drought_mean = np.array(drought_mean)\n",
    "drought_sem = np.array(drought_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_erafreq = []\n",
    "drought_erafreq = []\n",
    "yr_day_eracount = []\n",
    "years_era = []\n",
    "flood_eramean=[]\n",
    "flood_erasem =[]\n",
    "drought_eramean=[]\n",
    "drought_erasem =[]\n",
    "\n",
    "for year in range(min(df_era.index.year),max(df_era.index.year)):\n",
    "    tmp_yr_dat = df_era['ERA_anomaly'][df_era.index.year == year]  # pool data for each year\n",
    "    #print(tmp_yr_dat)\n",
    "    yr_day_eracount.append(tmp_yr_dat.count())\n",
    "    years_era.append(year)\n",
    "    #print(years_era)\n",
    "    if tmp_yr_dat.count() > 1:\n",
    "        flood_erafreq.append(len(tmp_yr_dat[wet_xtrm]))\n",
    "        #print(tmp_yr_dat[wet_xtrm])\n",
    "        drought_erafreq.append(len(tmp_yr_dat[dry_xtrm]))\n",
    "        flood_eramean.append(np.nanmean(tmp_yr_dat[wet_xtrm]))\n",
    "        flood_erasem.append(calc_SEM(tmp_yr_dat[wet_xtrm]))\n",
    "        drought_eramean.append(np.nanmean(tmp_yr_dat[dry_xtrm]))\n",
    "        drought_erasem.append(calc_SEM(tmp_yr_dat[dry_xtrm]))\n",
    "    else:\n",
    "        flood_erafreq.append(np.NAN)\n",
    "        drought_erafreq.append(np.NAN)\n",
    "     \n",
    "        flood_eramean.append(np.NAN)\n",
    "        flood_erasem.append(np.NAN)\n",
    "        drought_eramean.append(np.NAN)\n",
    "        drought_erasem.append(np.NAN)\n",
    "        \n",
    "flood_erafreq = np.array(flood_erafreq)\n",
    "drought_erafreq = np.array(drought_erafreq)\n",
    "yr_day_eracount = np.array(yr_day_eracount)\n",
    "years_era = np.array(years_era)\n",
    "flood_eramean = np.array(flood_eramean)\n",
    "flood_erasem = np.array(flood_erasem)\n",
    "drought_eramean = np.array(drought_eramean)\n",
    "drought_erasem = np.array(drought_erasem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drought_eramean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running_test = pd.rolling_mean(synthetic[\"vals\"], window=10, min_periods=3, center = True) \n",
    "int_rmean = pd.rolling_mean(flood_mean, window=10, min_periods=0, center = True)\n",
    "int_drmean = pd.rolling_mean(drought_mean, window=10, min_periods=0, center = True)\n",
    "#ERA\n",
    "era_rmean = pd.rolling_mean(flood_eramean, window=10, min_periods=0, center = True)\n",
    "era_drmean = pd.rolling_mean(drought_eramean, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Intensity of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Intensity\n",
    "my_int = plt.figure(dpi=72)\n",
    "my_int.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = my_int.add_subplot(121)\n",
    "ax2 = my_int.add_subplot(122)\n",
    "\n",
    "ax1.errorbar(years,flood_mean,  #Masking missing values\n",
    "             xerr=None, yerr=flood_sem,color='b', fmt='.', alpha=1.)\n",
    "ax1.errorbar(years_era, flood_eramean,xerr=None, yerr=flood_erasem,color='k', fmt='.', alpha=1.)\n",
    "\n",
    "ax1.plot(years, int_rmean,'g--', lw=2)\n",
    "ax1.plot(years_era, era_rmean,'k--', lw=2)\n",
    "ax1.set_title('Zone 2 Intensity of R90p events based on \\n statistical values of daily anomalies and percentiles', fontsize=14)\n",
    "ax1.set_ylabel(r'Intensity (mm day$^{-1}$)')\n",
    "ax1.set_xlabel(r'Year')\n",
    "leg1=ax1.legend(['Station data','RCA4_ERA'],prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "#ax1.set_ylim(0,12)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.errorbar(years,drought_mean,\n",
    "             xerr=None, yerr=drought_sem, color='r', fmt='.', alpha=1.)\n",
    "ax2.errorbar(years_era, drought_eramean,xerr=None, yerr=drought_erasem,color='k', fmt='.', alpha=1.)\n",
    "ax2.plot(years, int_drmean,'g--',alpha=1., lw=2)\n",
    "ax2.plot(years_era, era_drmean,'k--')\n",
    "ax2.set_title(' Zone 2 Intensity of R10p events based on \\n statistical values of daily anomalies and percentiles ', fontsize =14)\n",
    "ax2.set_xlabel(r\"Years\")\n",
    "ax2.set_ylabel('Intensity(mm day$^{-1}$)')\n",
    "leg1=ax2.legend(['Station data','RCA4_ERA'],prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax2.grid(True)\n",
    "#my_int.savefig('Zone2_Percentile_intensity+ERA1_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = np.polyfit(years[yr_day_count > 350], flood_mean[yr_day_count > 350], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##calc the trendline (linear fitting)\n",
    "trend = np.polyfit(flood_freq[yr_day_count > 350], years[yr_day_count > 350], len(flood_freq[yr_day_count > 350]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##calc the trendline (linear fitting)\n",
    "#from scipy.interpolate import spline\n",
    "#for year in range(min(df_prcp.index.year),max(df_prcp.index.year))\n",
    "#flood_freq_smooth = np.linspace9(min(flood_freq[yr_day_count > 350], \n",
    "        #                        max(flood_freq[yr_day_count > 350]) for for n, \n",
    "       #                         date in enumerate(tmp_yr_data.index[flood_freq], 10)\n",
    "#drought_freq_smooth = np.linspace(drought_freq.min(), drought_freq.max(), 10)\n",
    "#years_smooth = spline(flood_freq[yr_day_count > 350], years[yr_day_count > 350], \n",
    "                      #flood_freq_smooth)\n",
    "#plt.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350], 'b.', alpha=0.8)\n",
    "#plt.plot(years_smooth, flood_freq_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running_test = pd.rolling_mean(synthetic[\"vals\"], window=10, min_periods=3, center = True) \n",
    "fre_rmean = pd.rolling_mean(flood_freq, window=10, min_periods=0, center = True)\n",
    "fre_drmean = pd.rolling_mean(drought_freq, window=10, min_periods=0, center = True)\n",
    "#ERA\n",
    "erafreq_rmean = pd.rolling_mean(flood_erafreq, window=10, min_periods=0, center = True)\n",
    "erafreq_drmean = pd.rolling_mean(drought_erafreq, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.timedelta_range(start=None, end=None, periods=None, freq='D', name=None, closed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Frequency of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency \n",
    "my_ = plt.figure(dpi=72)\n",
    "my_.set_size_inches(15,5)        # Specify the output size\n",
    "ax = my_.add_subplot(121)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax1 = my_.add_subplot(122) \n",
    "\n",
    "\n",
    "ax.plot(years,flood_freq, 'b.', alpha=0.8)\n",
    "ax.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350], 'r.',alpha=0.8)\n",
    "leg=ax.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_title('Integer count of Extreme precip events(Frequency) \\n based on threshold value detection (Zone2)')\n",
    "ax.set_ylabel(r'Number of Extreme events (counts)')\n",
    "ax.set_xlabel('Years')\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350]/ #Normalized frequency\n",
    "        yr_day_count[yr_day_count > 350], 'b-', alpha=1.)\n",
    "ax1.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350]/\n",
    "        yr_day_count[yr_day_count > 350],'r-', alpha=1.)\n",
    "leg=ax1.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_title('Extreme precip events Frequency \\n based on threshold value detection(Zone2)')\n",
    "ax1.set_ylabel(r'Normalized count of Extreme events')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "plt.show(my_)\n",
    "#my_.savefig('Zone2_Percentile_Frequency_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency \n",
    "my_ = plt.figure(dpi=300)\n",
    "my_.set_size_inches(10,5)        # Specify the output size\n",
    "ax1 = my_.add_subplot(111) \n",
    "\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], fre_rmean[yr_day_count > 350]/yr_day_count[yr_day_count > 350],'b-', lw=2)\n",
    "ax1.plot(years[yr_day_count > 350], fre_drmean[yr_day_count > 350]/yr_day_count[yr_day_count > 350],'r-', lw=2)\n",
    "ax1.plot(years_era, erafreq_rmean/365,'g-',  lw=2)\n",
    "ax1.plot(years_era, erafreq_drmean/365,'k-',  lw=2)\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350]/yr_day_count[yr_day_count > 350], 'b.', alpha=1.)\n",
    "ax1.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350]/yr_day_count[yr_day_count > 350],'r.', alpha=1.)\n",
    "ax1.plot(years_era,flood_erafreq/yr_day_eracount, 'g.', alpha=0.8)\n",
    "ax1.plot(years_era,drought_erafreq/yr_day_eracount, 'k.', alpha=0.8)\n",
    "leg=ax1.legend(['Station data R90p','Station data R10p','RCA4_R90p','RCA4_R10p'],prop={'size':10},\n",
    "               numpoints=1,markerscale=1.,frameon=True,fancybox=True)\n",
    "ax1.set_title('Zone 2 Frequency of Extreme precip Events  \\n based on statistical values of daily anomalies and percentiles')\n",
    "ax1.set_ylabel(r'Normalized count of Extreme events')\n",
    "ax1.set_xlabel(r'Years')\n",
    "ax1.grid(True)\n",
    "plt.show(my_)\n",
    "#my_.savefig('Zone2_Percentile_ERAFrequency_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Duration of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration\n",
    "  * To look/do operations on time diffrences, this is called timedelta in the Pandas / datetime packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = tmp_yr_data[drought].index[1] - tmp_yr_data[drought].index[0]\n",
    "print(\"diffrence in days between first and second flood:\",test.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_days_since(df, truth_array, name_to_add):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe (df) as input, and a truth array\n",
    "    related to that dataframe (e.g. df=df_prcp, truth_array=drought)\n",
    "    and will then go through each date in the dataframe, look if the\n",
    "    truth value is True, and if it is, it will see how long since the\n",
    "    last truth value occured, and give an integer value (for day count)\n",
    "    which is then placed in an array, and appended to the original\n",
    "    dataframe at the end, with the name_to_add as the column name.\n",
    "    \"\"\"\n",
    "    days_since_list = []\n",
    "    last_day = df.index[0]  # Initilise the state of the 'last' day\n",
    "    for day in df.index:\n",
    "        if truth_array[day] == True:\n",
    "            days_since = day - last_day\n",
    "            days_since = int(days_since.days)\n",
    "            last_day = day  # update the state of last day to current true day\n",
    "            if days_since > 1000: # Just check the values aren't silly\n",
    "                days_since = np.NAN\n",
    "        else:\n",
    "            days_since = np.NAN\n",
    "        days_since_list.append(days_since)\n",
    "    days_since_list = np.array(days_since_list)\n",
    "    df[name_to_add]=days_since_list #adding column to the df_prcp data frame\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_days_since(df=df_prcp, truth_array=drought, name_to_add = 'DS_Last_D')#Days  since last drought\n",
    "add_days_since(df=df_prcp, truth_array=flood, name_to_add = 'DS_Last_F') #Days since last flood\n",
    "#add_days_since(df=df_prcp, truth_array=low_risk, name_to_add = 'DS_Last_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_duration = plt.figure()\n",
    "my_duration.set_size_inches(10,5)        \n",
    "ax1 = my_duration.add_subplot(111)\n",
    "#ax2 = my_duration.add_subplot(122) \n",
    "\n",
    "ax1.plot(df_prcp.DS_Last_F.index, df_prcp.DS_Last_F,'-b',ms=3.0,alpha=1.0, lw=2)\n",
    "ax1.plot(df_prcp.DS_Last_D.index, df_prcp.DS_Last_D,'-r',ms=3.0,alpha=1.0,lw=2)\n",
    "\n",
    "#ax1.bar(df_prcp.DS_Last_F.index, df_prcp.DS_Last_F, width=0.8, color = 'b')\n",
    "#ax1.bar(df_prcp.DS_Last_D.index, df_prcp.DS_Last_D, width=0.8, color = 'r')\n",
    "leg=ax1.legend(['DS_Last_R90p event','DS_Last_R10p',],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_ylabel(r'Duration since last event (Days) ')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_title(r'Duration between extreme events in Zone 2')\n",
    "ax1.set_ylim(0, 250)\n",
    "#ax1.set_xlim('1953-01-01','1990-12-31')\n",
    "ax1.grid(True)\n",
    "plt.show(my_duration)\n",
    "#my_duration.savefig('Zone2_Percentile_duration_curve.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(np.polyfit(df_prcp.DS_Last_F, df_prcp.DS_Last_F.index, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDD & CWD ###\n",
    "#### Consecutive dry days  & Consecutive wet days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdd_ERA = add_days_since(df=df_era, truth_array=df_era['ERAINT']<1 , name_to_add='RCA4_CDD')\n",
    "cdd_Obs = add_days_since(df=df_prcp, truth_array=df_prcp['Accumulated']<1 , name_to_add='CDD')\n",
    "cwd_ERA = add_days_since(df=df_era, truth_array=df_era['ERAINT']>=1 , name_to_add='RCA4_CWD')\n",
    "cwd_Obs = add_days_since(df=df_prcp, truth_array=df_prcp['Accumulated']>=1 , name_to_add='CWD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annera_cdd = df_era.RCA4_CDD.resample('A', how='mean')  \n",
    "annobs_cdd = df_prcp.CDD.resample('A', how='mean') \n",
    "annera_cwd = df_era.RCA4_CWD.resample('A', how='mean') \n",
    "annobs_cwd = df_prcp.CWD.resample('A', how='mean') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cddobs_rav = pd.rolling_mean(annobs_cdd, window=10, min_periods=0, center = True)\n",
    "cddera_rav = pd.rolling_mean(annera_cdd, window=10, min_periods=0, center = True)\n",
    "cwdobs_rav = pd.rolling_mean(annobs_cwd, window=10, min_periods=0, center = True)\n",
    "cwdera_rav = pd.rolling_mean(annera_cwd, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdd = plt.figure()\n",
    "cdd.set_size_inches(15,5)        \n",
    "ax1 = cdd.add_subplot(121)\n",
    "ax2 = cdd.add_subplot(122)\n",
    "\n",
    "ax1.plot(df_prcp.CDD.index, df_prcp.CDD,'b',ms=3.0,alpha=1.0,lw=2)\n",
    "ax1.plot(df_prcp.CWD.index, df_prcp.CWD,'r',ms=3.0,alpha=1.0,lw=2)\n",
    "\n",
    "leg=ax1.legend(['CDD','CWD'],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_ylabel(r'Duration since last event (Days) ')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_title(r'CDD & CWD over Zone 1 (Station data)')\n",
    "ax1.set_ylim(0,200)\n",
    "#ax1.set_xlim('1953-01-01','1990-12-31')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(df_era.RCA4_CDD.index, df_era.RCA4_CDD,'b',ms=3.0,alpha=1.0, lw=2)\n",
    "ax2.plot(df_era.RCA4_CWD.index, df_era.RCA4_CWD,'r',ms=3.0,alpha=1.0, lw=2)\n",
    "ax2.set_ylabel(r'Duration since last event (Days) ')\n",
    "ax2.set_xlabel('Years')\n",
    "ax2.set_title(r'CDD & CWD over Zone 1 (RCA4_ERA)')\n",
    "ax2.set_ylim(0,200)\n",
    "ax2.grid(True)\n",
    "\n",
    "\n",
    "leg=ax2.legend(['CDD','CWD'],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "plt.show(cdd)\n",
    "#cdd.savefig('Zone1_cdd.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Changes of annual maximum CWD and CDD\n",
    "cdd_mean = plt.figure()\n",
    "cdd_mean.set_size_inches(15,5)        \n",
    "ax1 = cdd_mean.add_subplot(121)\n",
    "ax2 = cdd_mean.add_subplot(122)\n",
    "\n",
    "ax1.plot(annobs_cdd.index, annobs_cdd,'b',ms=3.0,alpha=1.0,lw=1)\n",
    "ax1.plot(annobs_cwd.index, annobs_cwd,'r',ms=3.0,alpha=1.0,lw=1)\n",
    "ax1.plot(cddobs_rav.index, cddobs_rav,'b--',ms=3.0,alpha=1.0,lw=2)\n",
    "ax1.plot(cwdobs_rav.index, cwdobs_rav,'r--',ms=3.0,alpha=1.0,lw=2)\n",
    "\n",
    "leg=ax1.legend(['CDD','CWD'],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_ylabel(r'Annual Mean Duration since last event (Days) ')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_title(r'CDD & CWD over Zone 1 (Station data)')\n",
    "ax1.set_ylim(0,10)\n",
    "ax1.set_xlim('1953-01-01','2015-12-31')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(annera_cdd.index, annera_cdd,'b',ms=3.0,alpha=1.0, lw=1)\n",
    "ax2.plot(annera_cwd.index, annera_cwd,'r',ms=3.0,alpha=1.0, lw=1)\n",
    "ax2.plot(cddera_rav.index, cddera_rav,'b--',ms=3.0,alpha=1.0, lw=2)\n",
    "ax2.plot(cwdera_rav.index, cwdera_rav,'r--',ms=3.0,alpha=1.0, lw=2)\n",
    "ax2.set_ylabel(r'Annual Mean Duration since last event (Days) ')\n",
    "ax2.set_xlabel('Years')\n",
    "ax2.set_title(r'CDD & CWD over Zone 1 (RCA4_ERA)')\n",
    "ax2.set_ylim(0,10)\n",
    "ax2.grid(True)\n",
    "\n",
    "\n",
    "leg=ax2.legend(['CDD','CWD'],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "#cdd_mean.savefig('Zone1_cdd_annual.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Changes of annual maximum CWD and CDD\n",
    "cdd_mean1 = plt.figure()\n",
    "cdd_mean1.set_size_inches(10,5)        \n",
    "ax1 = cdd_mean1.add_subplot(111)\n",
    "\n",
    "ax1.plot(annobs_cdd.index, annobs_cdd,'b',ms=3.0,alpha=1.0,lw=1.5)\n",
    "ax1.plot(annobs_cwd.index, annobs_cwd,'r',ms=3.0,alpha=1.0,lw=1.5)\n",
    "ax1.plot(annera_cdd.index, annera_cdd,'g',ms=3.0,alpha=1.0, lw=1.5)\n",
    "ax1.plot(annera_cwd.index, annera_cwd,'k',ms=3.0,alpha=1.0, lw=1.5)\n",
    "ax1.plot(cddobs_rav.index, cddobs_rav,'b--',ms=3.0,alpha=1.0,lw=2.5)\n",
    "ax1.plot(cwdobs_rav.index, cwdobs_rav,'r--',ms=3.0,alpha=1.0,lw=2.5)\n",
    "ax1.plot(cddera_rav.index, cddera_rav,'g--',ms=3.0,alpha=1.0, lw=2.5)\n",
    "ax1.plot(cwdera_rav.index, cwdera_rav,'k--',ms=3.0,alpha=1.0, lw=2.5)\n",
    "\n",
    "leg=ax1.legend(['Station data CDD','Station data CWD','RCA4_ERA CDD','RCA4_ERA CWD'],\n",
    "               prop={'size':10},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_ylabel(r'Annual Mean Duration since last event (Days)')\n",
    "ax1.set_xlabel('Years', fontsize=15)\n",
    "ax1.set_title(r'CDD & CWD over Zone 1', fontsize=15)\n",
    "ax1.set_ylim(0,10)\n",
    "#ax1.set_xlim('1954-01-01','1985-12-31')\n",
    "ax1.grid(True)\n",
    "\n",
    "#cdd_mean1.savefig('Zone1_cdd_Sum.pdf',dpi=300)\n",
    "#Duration between last CDD is increasing while that of CWD is declining, meaning more days "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extreme event based on cumulative statistical values (boxcar approach)###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Type of boxcar function\n",
    "\"\"\"\n",
    "Interested in the sum of mean precip for current day plus the next 2 days\n",
    "If the sum is greater than 100mm, then this could be a signal\n",
    "for potential medium-high risk for flood, low risk if greater than 50mm but\n",
    "less than 100. \n",
    "\"\"\"\n",
    "#RX3day: maximum 3-d Precipitation : Highest precipitation amount in 3-d period\n",
    "running_total = pd.rolling_sum(df_prcp[\"Accumulated\"], window=3, min_periods=3, center = True) #inverse=[::-1]\n",
    "print(np.max(running_total), np.max(df_prcp[\"Accumulated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(running_total[7000:7005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RX5day: maximum 5-d Precipitation : Highest precipitation amount in 5-d period###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "running_total5d = pd.rolling_sum(df_prcp[\"Accumulated\"], window=5, min_periods=5, center = True) #inverse=[::-1]\n",
    "print(np.max(running_total5d), np.max(df_prcp[\"Accumulated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_total = plt.figure()\n",
    "my_total.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = my_total.add_subplot(121)\n",
    "ax2 = my_total.add_subplot(122)\n",
    "\n",
    "ax1.plot(running_total.index, running_total,'.g',ms=3.0,alpha=0.75)\n",
    "ax1.plot(running_total[running_total > 50].index, running_total[running_total > 50],'.r',ms=3.0,alpha=1.0)\n",
    "leg=ax1.legend(['No risk','flood risk',],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "ax1.set_ylabel(r'Precipitation (mm day$^{-1}$)',fontsize =14)\n",
    "ax1.set_xlabel('Years',fontsize =14)\n",
    "ax1.set_title(r'RX3day: maximum 3-d Precipitation in East Africa',fontsize =14)\n",
    "ax1.set_ylim(0, 120)\n",
    "ax1.set_xlim('1952-01-01','2015-12-31')\n",
    "ax1.grid(True)\n",
    "\n",
    "\n",
    "ax2.plot(running_total5d.index, running_total5d,'.g',ms=3.0,alpha=0.75)\n",
    "ax2.plot(running_total5d[running_total5d > 50].index, running_total5d[running_total5d > 50],'.r',ms=3.0,alpha=1.0)\n",
    "leg=ax2.legend(['No risk','flood risk',],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "ax2.set_ylabel(r'Precipitation (mm day$^{-1}$)',fontsize =14)\n",
    "ax2.set_xlabel('Years', fontsize =14)\n",
    "ax2.set_title(r'RX5day: Maximum 5-d Precipitation in East Africa',fontsize =14)\n",
    "ax2.set_ylim(0, 120)\n",
    "ax2.set_xlim('1952-01-01','2015-12-31')\n",
    "ax2.grid(True)\n",
    "plt.show(my_total)\n",
    "#my_total.savefig('Zone1_total_ts.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics####\n",
    "###### Frequency of flood risk events based on cumulative statistical values (boxcar approach)######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_risk = running_total[running_total > 50]   #Gives days when precipitation 3-d precip totals exceeded the flood\n",
    "flood_risk5d = running_total5d[running_total5d > 50] #threshold\n",
    "\n",
    "floodrisk_freq = flood_risk.groupby( flood_risk.index.year).count()/365   #Gives Noramlized frequency    \n",
    "floodrisk_freq5d = flood_risk5d.groupby( flood_risk5d.index.year).count()/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r3mean = pd.rolling_mean(flood_risk, window=10, min_periods=0, center = True)\n",
    "r5mean = pd.rolling_mean(flood_risk5d, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency plot \n",
    "flood_freq = plt.figure()\n",
    "flood_freq.set_size_inches(15,5)        \n",
    "ax1 = flood_freq.add_subplot(121)\n",
    "ax2 = flood_freq.add_subplot(122)\n",
    "\n",
    "ax1.plot(floodrisk_freq.index, floodrisk_freq ,'r.',ms=7.0,alpha=1.)\n",
    "#ax1.plot(r3mean.index, r3mean ,'r-',ms=3.0,alpha=1.)\n",
    "ax1.set_title('Flood risk events Frequency RX3day (Zone1) based on\\n cumulative statistical values (boxcar approach)')\n",
    "ax1.set_ylabel(r'Normalized count of events')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(floodrisk_freq5d.index, floodrisk_freq5d ,'r.',ms=7.0,alpha=1.)\n",
    "#ax2.plot(floodrisk_freq5d.index, r3mean ,'r-',ms=3.0,alpha=1.)\n",
    "ax2.set_title('Flood risk events Frequency RX5day (Zone1) based on\\n cumulative statistical values (boxcar approach)')\n",
    "ax2.set_ylabel(r'Normalized count of events')\n",
    "ax2.set_xlabel(r'Year')\n",
    "ax2.grid(True)\n",
    "#flood_freq.savefig('Zone1_RX3d.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Duration of flood risk events based on cumulative statistical values (boxcar approach)######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####From the Frequency of occurance its evident that duration between flood events takes upto 22 years (1967-1989)### \n",
    "#####TO DO running means, with no threashold limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "running_mean = pd.rolling_mean(df_prcp[\"Accumulated\"], window=10, min_periods=3, center = True)\n",
    "print(np.max(running_mean), np.max(df_prcp[\"Accumulated\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Correlation Analysis###\n",
    "##### Relationship between monthly climate indices anom. & extreme precips#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_index(dt):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the YR, MON of indices into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(dt)\n",
    "    return pd.datetime((int(dstring[0:4]),int(dstring[4:6]))) #year Month\n",
    "                       \n",
    "def corr_df(fpath, label, clim_index):\n",
    "    print(fpath)\n",
    "    for file in glob.glob(fpath):\n",
    "        data_in = pd.read_fwf(file)\n",
    "        \n",
    "        data = []\n",
    "        dates = [date_index(entry) for entry in corr_df.index]\n",
    "        for month in range(12,):\n",
    "                dates.append(corr_df(corr_df.Year[entry]).month())\n",
    "                data.append(data_in)\n",
    "    return pd.DataFrame(data=data, column=[label], index=dates)                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching data from web source using Pandas #####\n",
    "\n",
    "[IOD data](http://stateoftheocean.osmc.noaa.gov/sur/ind/dmi.php),  \n",
    "[ENSO data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/ersst3b.nino.mth.81-10.ascii),   \n",
    "[SOI data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/soi),   \n",
    "[QBO30mb data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/qbo.u30.index),   \n",
    "[QBO50mb data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/qbo.u50.index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enso_path = 'ftp://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/ersst3b.nino.mth.81-10.ascii'\n",
    "#enso_data = pd.read_fwf(enso_path)\n",
    "#enso_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is aimed at finding the relationship between extreme weather events \n",
    "in EA and climate indices(ENSO, QBO, IOD), Also what is the correlation  \n",
    "between the data (and their statistical significance)?\n",
    "\"\"\"\n",
    "#iod=pd.read_fwf(\"Data/dmi.nc\")\n",
    "enso=pd.read_fwf(\"Data/noaa_mei.txt\")\n",
    "soi = pd.read_fwf(\"Data/noaa_soi.txt\", index_col='YEAR')\n",
    "qbo30 =pd.read_fwf(\"Data/noaa_qbo30.txt\", index_col='YEAR')\n",
    "qbo50 = pd.read_fwf(\"Data/noaa_qbo50.txt\", index_col='YEAR')\n",
    "# Make the year integers the index\n",
    "enso.index = pd.date_range(start='1950-01-01',end='2015-07-01',freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_list = soi.keys()\n",
    "tmp_data = []\n",
    "for year in soi.index:\n",
    "    for month in month_list:\n",
    "        tmp_data.append(soi[month][year])\n",
    "        #print(month,year,soi[month][year])\n",
    "tmp_data = np.array(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mon_list = qbo30.keys()\n",
    "qbo3_data = []\n",
    "qbo5_data = []\n",
    "for year in qbo30.index:\n",
    "    for month in mon_list:\n",
    "        qbo3_data.append(qbo30[month][year])\n",
    "        qbo5_data.append(qbo50[month][year])\n",
    "        #print(month,year,qbo30[month][year])\n",
    "qbo3_data = np.array(qbo3_data)\n",
    "qbo5_data = np.array(qbo5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating their data frames\n",
    "df_soi = pd.DataFrame(data=tmp_data,index=pd.date_range(start='1951-01-01',end='2015-12-31',freq='M'),columns=['SOI'])\n",
    "df_qbo3=pd.DataFrame(data=qbo3_data,index=pd.date_range(start='1979-01-01',end='2015-12-31',freq='M'),columns=['QBO3'])\n",
    "df_qbo5=pd.DataFrame(data=qbo5_data,index=pd.date_range(start='1979-01-01',end='2015-12-31',freq='M'),columns=['QBO5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to convert a DataFrame to a TimeSeries\n",
    "soii = df_soi.unstack()\n",
    "qbo3 = df_qbo3.unstack()\n",
    "qbo5 = df_qbo5.unstack()\n",
    "print(np.mean(soii), np.mean(qbo3), np.mean(qbo5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Indian Ocean Dipole Index \n",
    "import netCDF4\n",
    "f = netCDF4.Dataset(\"Data/dmi.nc\") # Assign the netcdf file\n",
    "#print(f.variables)                # Show what is in the netcdf file\n",
    "dmi = f[\"DMI\"][:]                  # Call the DMI and dates and assign them to a variable\n",
    "dmi_date = f[\"WEDCEN2\"][:]\n",
    "dmi_dates = netCDF4.num2date(f['WEDCEN2'][:],units = f['WEDCEN2'].units)\n",
    "dmi_index = pd.to_datetime(dmi_dates)\n",
    "f.close()                        # close the connection to the netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_iod = pd.DataFrame(data=dmi,index=dmi_index,columns=['IOD']) \n",
    "iod = df_iod.unstack()    #convert a DataFrame to a TimeSeries\n",
    "dmi_mon = df_iod['IOD'].resample('M', how='mean') #Resampling the weekly IOD data into monthly for correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible dependent Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_monthly = df_prcp.Acc_anomaly.resample('M', how='mean') #monthly Deseasonalized precip \n",
    "era_monthly = df_era.ERA_anomaly.resample('M', how = 'mean')\n",
    "extreme_monthly = df_prcp[\"Acc_anomaly\"][extremes].resample('M', how='mean') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with ENSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plots to explore the data\n",
    "enso_fig = plt.figure(dpi=72)\n",
    "enso_fig.set_size_inches(20,5)        \n",
    "ax = enso_fig.add_subplot(111)\n",
    "\n",
    "ax.plot(acc_monthly['1955-01-01':'1990-12-31'].index,acc_monthly['1955-01-01':'1990-12-31'], 'b',ms=3.0,alpha=0.75) \n",
    "ax.plot(era_monthly['1981-01-01':'1990-12-31'].index,era_monthly['1981-01-01':'1990-12-31'], 'g',ms=3.0,alpha=0.75) \n",
    "ax.plot(enso['1955-01-01':'1990-12-31'].index,enso['ANOM.3']['1955-01-01':'1990-12-31'], 'r',ms=3.0,alpha=0.75)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_dat = acc_monthly['1961-01-01':'1990-12-31'] == acc_monthly['1961-01-01':'1990-12-31']\n",
    "good_era = era_monthly['1981-01-01':'2010-12-31'] == era_monthly['1981-01-01':'2010-12-31']\n",
    "enso_stats = stats.linregress(enso['ANOM.3']['1961-01-01':'1990-12-31'][good_dat],\n",
    "                             acc_monthly['1961-01-01':'1990-12-31'][good_dat])\n",
    "enso_stats\n",
    "#Results shows a very low (<10%) correlation of EA monthly precipitation with ENSO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "era_stats = stats.linregress(enso['ANOM.3']['1981-01-01':'2010-12-31'][good_era],\n",
    "                             era_monthly['1981-01-01':'2010-12-31'][good_era])\n",
    "era_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_enso = plt.figure(dpi=72)\n",
    "corr_enso.set_size_inches(5,5)        \n",
    "ax1 = corr_enso.add_subplot(111)\n",
    "\n",
    "ax1.plot(enso['ANOM.3']['1961-01-01':'1990-12-31'],acc_monthly['1961-01-01':'1990-12-31'],'r.')\n",
    "ax1.plot(enso['ANOM.3']['1981-01-01':'2010-12-31'],era_monthly['1981-01-01':'2010-12-31'],'b.')\n",
    "fit = np.arange(-3,3,0.1)*enso_stats[0] + enso_stats[0]\n",
    "fit1 = np.arange(-3,3,0.1)*era_stats[0] + era_stats[0]\n",
    "ax1.plot(np.arange(-3,3,0.1), fit, 'r-')\n",
    "ax1.plot(np.arange(-3,3,0.1), fit1, 'b-')\n",
    "ax1.set_ylabel(r'Monthly Precip (Anomalies)', fontsize=14)\n",
    "ax1.set_title(' ENSO Scatter plot Zone 1', fontsize=14)\n",
    "ax1.set_xlabel(r'ENSO(3.4) Index', fontsize=14)\n",
    "\n",
    "corr_enso.text(0.4, 0.85, r'r = 0.0821 - Station data' ,fontsize=12,color='r')\n",
    "corr_enso.text(0.4, 0.80, r'r = -0.025 - RCA4_ERA' ,fontsize=12,color='b')\n",
    "#corr_enso.savefig('Zone2_Index_ENSO+ERA.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_dt = acc_monthly['1997'] == acc_monthly['1997']\n",
    "enso_stat = stats.linregress(enso['ANOM.3']['1997'][good_dt],\n",
    "                             acc_monthly['1997'][good_dt])\n",
    "enso_stat\n",
    "#Results shows significant (67%) correlation of EA monthly precipitation during the 97/98\n",
    "#El nino episode ###Interesting ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rvalue=0.59\n",
    "print(\"r-squared:\", rvalue**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with SOI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(acc_monthly['1955 -01-01':'1990-12-30'].index,acc_monthly['1955-01-01':'1990-12-30'])\n",
    "plt.plot(df_soi['1955-01-01':'1990-12-30'].index, df_soi['1955-01-01':'1990-12-30']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soi_stats = stats.linregress(df_soi['SOI']['1961-01-01':'1990-12-31'][good_dat],\n",
    "                             acc_monthly['1961-01-01':'1990-12-31'][good_dat])\n",
    "soiera_stats = stats.linregress(df_soi['SOI']['1981-01-01':'2010-12-31'][good_era],\n",
    "                             era_monthly['1981-01-01':'2010-12-31'][good_era])\n",
    "print(\"soi correlation statistics:\",soi stats)\n",
    "print(\"RCA4, soi correlation_stats:\",soiera_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with QBO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_qbo5['QBO5'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qbo_gd = acc_monthly['1981-01-01':'1990-12-31'] == acc_monthly['1981-01-01':'1990-12-31']\n",
    "qbo3_stats = stats.linregress(df_qbo3['QBO3']['1981-01-01':'1990-12-31'][qbo_gd],\n",
    "                             acc_monthly['1981-01-01':'1990-12-31'][qbo_gd])\n",
    "qbo3era_stats = stats.linregress(df_qbo3['QBO3']['1981-01-01':'2010-12-31'][good_era],\n",
    "                             era_monthly['1981-01-01':'2010-12-31'][good_era])\n",
    "print(\"QBO correlation statistics:\",qbo3_stats)\n",
    "print(\"RCA4,  QBO correlation_stats:\",qbo3era_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with IOD ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iod = plt.figure(dpi=72)\n",
    "iod.set_size_inches(15,5)        \n",
    "ax = iod.add_subplot(111)\n",
    "#plt.plot(acc_monthly['1981-01-01':'2006-12-31'].index, acc_monthly['1981-01-01':'2006-12-31']) \n",
    "ax.plot(OND_iod.index, OND_iod, 'r')\n",
    "ax.plot(OND_Obs.index, OND_Obs, 'b')\n",
    "#ax.plot(enso['1981-08-01':'2015-12-31'].index, enso['ANOM.3']['1981-08-01':'2015-12-31'], 'b')\n",
    "\n",
    "ax.set_title(' Monthly IOD index Time Series ')\n",
    "ax.set_xlabel(r'Time')\n",
    "ax.set_ylabel(r'IOD Index ($^{o}$C)')\n",
    "ax.grid(True)\n",
    "#iod.savefig('Zone1_IOD.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.linregress(dmi_mon,dmi_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Regression of Monthly anomalized data with IOD\n",
    "gd_data = acc_monthly['1981-11-30':'1990-12-31'] == acc_monthly['1981-11-30':'1990-12-31']\n",
    "iod_stats = stats.linregress(dmi_mon['1981-11-30':'1990-12-31'][gd_data],\n",
    "                             acc_monthly['1981-11-30':'1990-12-31'][gd_data])\n",
    "iodera_stats = stats.linregress(dmi_mon['1981-11-30':'2010-12-31'][good_era],\n",
    "                             era_monthly['1981-11-30':'2010-12-31'][good_era])\n",
    "print(iod_stats)\n",
    "print(iodera_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Regression of Seasonal anomalized data with IOD\n",
    "dat = acc_seasonal['1981-11-30':'2015-08-31'] == acc_seasonal['1981-11-30':'2015-08-31']\n",
    "iod_ssn = stats.linregress(dmi_seasonal['1981-11-30':'2015-08-31'][dat],\n",
    "                             acc_seasonal['1981-11-30':'2015-08-31'][dat])\n",
    "iod_ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_iod = plt.figure(dpi=72)\n",
    "corr_iod.set_size_inches(5,5)        \n",
    "ax1 = corr_iod.add_subplot(111)\n",
    "\n",
    "ax1.plot(dmi_mon['1981-11-30':'1990-08-31'],acc_monthly['1981-11-30':'1990-08-31'],'r.')\n",
    "fit = np.arange(-3,3,0.1)*iod_stats[0] + iod_stats[0]\n",
    "ax1.plot(np.arange(-3,3,0.1), fit, 'r-')\n",
    "ax1.set_ylabel(r'Monthly Precip (Anomalies)')\n",
    "ax1.set_title('IOD Scatter plot for Zone 1')\n",
    "ax1.set_xlabel(r'IOD Index ')\n",
    "\n",
    "corr_iod.text(0.4, 0.85, r'r = -0.0097' ,fontsize=12,color='b')\n",
    "#corr_iod.savefig('Zone1_Index_IOD.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Correlations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = acc_monthly.index.month\n",
    "selectors = enso['ANOM.3'].index.month\n",
    "selectorss  = dmi_mon.index.month\n",
    "selector_era = era_monthly.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "era_monthly[selector_era == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_corr = plt.figure(dpi=300)\n",
    "monthly_corr.set_size_inches(15,5)        \n",
    "ax = monthly_corr.add_subplot(111)\n",
    "\n",
    "ax.plot(acc_monthly[selector == 11].index, acc_monthly[selector ==11], 'b', ms=3.0,alpha=0.75) \n",
    "ax.plot(enso['ANOM.3'][selectors==11].index, enso['ANOM.3'][selectors==11], 'r', ms=3.0,alpha=0.75)\n",
    "ax.plot(dmi_mon[selectorss==11].index,dmi_mon[selectorss==11], 'g', ms=3.0,alpha=0.75)\n",
    "leg=ax.legend(['Precip','ENSO3.4 Index','IOD Index'],prop={'size':12},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_ylabel(r'Anomalies')\n",
    "ax.set_title(' Relationship of EA precips Vs ENSO Index & IOD Index for the Month of November (Zone 1) ')\n",
    "ax.set_xlabel(r'Time (months_Nov)')\n",
    "ax.grid(True)\n",
    "#monthly_corr.savefig('Zone1_Correlation_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gd = acc_monthly[selector == 5]['1955-01-01':'1990-12-31'] == acc_monthly[selector == 5]['1955-01-01':'1990-12-31']\n",
    "stats = stats.linregress(enso['ANOM.3'][selectors==5]['1955-01-01':'1990-12-31'][gd],\n",
    "                             acc_monthly[selector==5]['1955-01-01':'1990-12-31'][gd])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_mon = plt.figure(dpi=72)\n",
    "corr_mon.set_size_inches(5,5)        \n",
    "ax1 = corr_mon.add_subplot(111)\n",
    "\n",
    "ax1.plot(enso['ANOM.3'][selectors==11]['1955-01-01':'1990-12-31'], \n",
    "         acc_monthly[selector==11]['1955-01-01':'1990-12-31'],'r.')\n",
    "fit = np.arange(-3,3,0.1)*stats[0] + stats[0]\n",
    "ax1.plot(np.arange(-3,3,0.1), fit, 'r-')\n",
    "ax1.set_ylabel(r'May precip (mm)')\n",
    "ax1.set_title('MAY (ENSO) Scatter plot Zone 1')\n",
    "ax1.set_xlabel(r' ENSO Index ($^{o}$C)')\n",
    "\n",
    "corr_mon.text(0.2, 0.85, r'r = -0.20968898413341716' ,fontsize=12,color='b')\n",
    "#corr_mon.savefig('Zone1_Index_MAY.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gd1 = acc_monthly[selector == 10]['1955-01-01':'2015-08-31'] == acc_monthly[selector == 10]['1955-01-01':'2015-08-31']\n",
    "stat = stats.linregress(enso['ANOM.3'][selectors==10]['1955-01-01':'2015-08-31'][gd1],\n",
    "                             acc_monthly[selector==10]['1955-01-01':'2015-08-31'][gd1])\n",
    "stat\n",
    "#High r values Mar=-30% April=25% May =44% Oct=35%, Nov=34% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gd2 = acc_monthly[selector == 11]['1982-01-01':'2015-08-31'] == acc_monthly[selector == 11]['1982-01-01':'2015-08-31']\n",
    "mon_stats = stats.linregress(dmi_mon[selectorss==11]['1982-01-01':'2015-08-31'][gd2],\n",
    "                             acc_monthly[selector==11]['1982-01-01':'2015-08-31'][gd2])\n",
    "mon_stats\n",
    "#High r values June=29% May=42% Oct=42%, Nov=70% Dec=20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_mon1 = plt.figure(dpi=72)\n",
    "corr_mon1.set_size_inches(5,5)        \n",
    "ax1 = corr_mon1.add_subplot(111)\n",
    "\n",
    "ax1.plot(dmi_mon[selectorss==11]['1982-01-01':'2015-08-31'], \n",
    "         acc_monthly[selector==11]['1982-01-01':'2015-08-31'],'r.')\n",
    "fit = np.arange(-3,3,0.1)*mon_stats[0] + mon_stats[0]\n",
    "ax1.plot(np.arange(-3,3,0.1), fit, 'r-')\n",
    "ax1.set_ylabel(r'Nov precip (mm)')\n",
    "ax1.set_title('November (IOD) Scatter plot')\n",
    "ax1.set_xlabel(r' IOD Index ($^{o}$C)')\n",
    "\n",
    "corr_mon1.text(0.2, 0.85, r'r = 0.69899981717326531' ,fontsize=12,color='b')\n",
    "#corr_mon1.savefig('Zone2_Index_NOVIOD.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Correlarion statistics ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expoloring here the seasonal correlations\n",
    "'''\n",
    "To do seasonal anomaly correlation\n",
    "'''\n",
    "acc_seasonal = acc_monthly.resample('Q', how='mean') #Seasons \"JFM, AMJ, JAS, OND\"\n",
    "xtrm_seasonal = extreme_monthly.resample('Q', how='mean') #Seasons \"JFM, AMJ, JAS, OND\"\n",
    "era_seasonal = era_monthly.resample('Q', how='mean')\n",
    "enso_seasonal = enso['ANOM.3'].resample('Q', how='mean') \n",
    "dmi_seasonal = df_iod['IOD'].resample('Q', how='mean')\n",
    "soi_seasonal = df_soi['SOI'].resample('Q', how='mean')\n",
    "qbo_seasonal = df_qbo3['QBO3'].resample('Q', how='mean')\n",
    "\n",
    "#acc_ssn = acc_monthly.resample('BQ-FEB', how = 'mean') #Seasons \"DJF, MAM, JJA, SON\"\n",
    "#enso_ssn = enso['ANOM.3'].resample('BQ-FEB', how='mean') #Seasons \"DJF, MAM, JJA, SON\"\n",
    "#dmi_ssn = df_iod['IOD'].resample('BQ-FEB', how='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = acc_seasonal.index.month\n",
    "x1 = enso_seasonal.index.month\n",
    "x2 = era_seasonal.index.month\n",
    "x3 = xtrm_seasonal.index.month\n",
    "x4 = dmi_seasonal.index.month\n",
    "x5 = soi_seasonal.index.month\n",
    "x6 = qbo_seasonal.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OND_Obs = acc_seasonal[x == 12]\n",
    "OND_ens = enso_seasonal[x1 == 12]\n",
    "OND_era = era_seasonal[x2 == 12]\n",
    "OND_xtr = xtrm_seasonal[x3 == 12]\n",
    "OND_iod = dmi_seasonal[x4 == 12]\n",
    "OND_soi = soi_seasonal[x5 == 12]\n",
    "OND_qbo = qbo_seasonal[x6 == 12]\n",
    "# JJAS season was used for zone 1 while OND used in Zone 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clima = plt.figure()\n",
    "clima.set_size_inches(15,5)        \n",
    "ax = clima.add_subplot(111)\n",
    "ax.plot(OND_xtr.index, OND_xtr, 'r', ms=3.0,alpha=1.0,lw=2)\n",
    "ax.plot(OND_ens.index, OND_ens, 'b', ms=3.0,alpha=1.0,lw=2)\n",
    "ax.plot(OND_soi.index, OND_soi, 'g', ms=3.0,alpha=1.0,lw=2)\n",
    "ax.set_title(' JJAS Average ENSO/SOI Indices Correlation with Zone 1 Extreme Precipitation ', fontsize = 15)\n",
    "ax.set_xlabel(r'Years', fontsize = 15)\n",
    "ax.set_ylabel(r'Anomaly ', fontsize = 15)\n",
    "ax.set_xlim('1950', '1990')\n",
    "ax.set_ylim(-5,7)\n",
    "leg=ax.legend(['Station data','ENSO 3.4','SOI'],prop={'size':10},\n",
    "              numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax.grid(True)\n",
    "#clima.savefig('Zone1_ClimIndices_EXtreme.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clim = plt.figure()\n",
    "clim.set_size_inches(15,5)        \n",
    "ax = clim.add_subplot(111)\n",
    "ax.plot(OND_Obs.index, OND_Obs, 'r', ms=3.0,alpha=1.0,lw=2)\n",
    "ax.plot(OND_era.index, OND_era, 'k', ms=3.0,alpha=1.0,lw=3)\n",
    "ax.plot(OND_ens.index, OND_ens, 'b', ms=3.0,alpha=1.0,lw=2)\n",
    "ax.plot(OND_iod.index, OND_iod, 'g', ms=3.0,alpha=1.0,lw=2)\n",
    "#ax.plot(OND_soi.index, OND_soi, 'm', ms=3.0,alpha=1.0,lw=1.5)\n",
    "#ax.plot(OND_qbo.index, OND_qbo, 'y', ms=3.0,alpha=1.0,lw=1.5)\n",
    "\n",
    "ax.set_title(' JJAS Average ENSO/SOI Indices Correlation with Zone 1 Precipitation ', fontsize = 15)\n",
    "ax.set_xlabel(r'Years', fontsize = 15)\n",
    "ax.set_ylabel(r'Anomaly ', fontsize = 15)\n",
    "ax.set_xlim('1952', '2014')\n",
    "ax.set_ylim(-5,8)\n",
    "leg=ax.legend(['Station data','RCA4','ENSO 3.4','IOD','SOI','QBO'],prop={'size':10},\n",
    "              numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "ax.grid(True)\n",
    "#clim.savefig('Zone1_ClimIndices_ENSO+SOI.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssn_ensostats = stats.linregress(OND_ens['1981-12-31':'2010-12-31'], OND_era['1981-12-31':'2010-12-31'])\n",
    "ssn_soistats =stats.linregress(OND_soi['1981-12-31':'2010-12-31'], OND_era['1981-12-31':'2010-12-31'])\n",
    "ssn_iodstats =stats.linregress(OND_iod['1981-12-31':'2010-12-31'], OND_era['1981-12-31':'2010-12-31'])\n",
    "ssn_qbostats =stats.linregress(OND_qbo['1981-12-31':'2010-12-31'], OND_era['1981-12-31':'2010-12-31'])\n",
    "print(\"ENSO Correlation Stats:\",ssn_ensostats)\n",
    "print(\"SOI Correlation Stats:\",ssn_soistats)\n",
    "print(\"IOD Correlation Stats:\",ssn_iodstats)\n",
    "print(\"QBO Correlation Stats:\",ssn_qbostats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enso_sca = plt.figure()\n",
    "enso_sca.set_size_inches(5,5)        \n",
    "ax1 = enso_sca.add_subplot(111)\n",
    "\n",
    "ax1.plot(OND_ens['1981-12-31':'2010-12-31'], OND_era['1981-12-31':'2010-12-31'],'ro')\n",
    "fit = np.arange(-3,3,0.1)*ssn_ensostats[0] + ssn_ensostats[0]\n",
    "ax1.plot(np.arange(-3,3,0.1), fit, 'r-', lw=2)\n",
    "ax1.set_ylabel(r'Precipitation Anomalies', fontsize=14)\n",
    "ax1.set_title(' Relationship between RCA4 Rain and SOI in Zone 2', fontsize=12)\n",
    "ax1.set_xlabel(r'ENSO(3.4) Index', fontsize=14)\n",
    "ax1.grid(True)\n",
    "\n",
    "enso_sca.text(0.4, 0.85, r'rvalue = 0.47 ' ,fontsize=13,color='b')\n",
    "enso_sca.text(0.4, 0.80, r'slope =  0.22 ' ,fontsize=13,color='b')\n",
    "enso_sca.text(0.4, 0.75, r'pvalue = 0.01 ' ,fontsize=13,color='b')\n",
    "\n",
    "#enso_sca.savefig('Zone2_Index-ENSO_RCA4.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_var = acc_monthly\n",
    "ind_var =[[enso['ANOM.3']], [soii], [qbo3], [qbo5]]\n",
    "\n",
    "\n",
    "def reg_m(dep_var, ind_var):\n",
    "    ones = np.ones(len(dep_var[0]))\n",
    "    X = sm.add_constant(np.column_stack((dep_var[0], ones)))\n",
    "    for ele in dep_var[1:]:\n",
    "        dep_var = sm.add_constant(np.column_stack((ele, dep_var)))\n",
    "    results = sm.OLS(ind_var, dep_var).fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(reg_m(dep_var, ind_var).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = [1,2,3,4,3,4,5,4,5,5,4,5,4,5,4,5,6,5,4,5,4,3,4]\n",
    "\n",
    "x = [\n",
    "     [4,2,3,4,5,4,5,6,7,4,8,9,8,8,6,6,5,5,5,5,5,5,5],\n",
    "     [4,1,2,3,4,5,6,7,5,8,7,8,7,8,7,8,7,7,7,7,7,6,5],\n",
    "     [4,1,2,5,6,7,8,9,7,8,7,8,7,7,7,7,7,7,6,6,4,4,4]\n",
    "     ]\n",
    "\n",
    "def reg_m(y, x):\n",
    "    ones = np.ones(len(x[0]))\n",
    "    X = sm.add_constant(np.column_stack((x[0], ones)))\n",
    "    for ele in x[1:]:\n",
    "        X = sm.add_constant(np.column_stack((ele, X)))\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(reg_m(y, x).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_monthly.groupby(['month']).groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enso['ANOM.3'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enso['MON'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_index = []\n",
    "tmp_data = []\n",
    "for entry in enso.index:\n",
    "    for MON in range(12,):\n",
    "            tmp_index.append(pd.datetime(enso.YR[entry]).MON())\n",
    "            tmp_data.append(entry)\n",
    "tmp_index = np.array(tmp_index)\n",
    "tmp_data = np.array(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_enso = pd.DataFrame(data=tmp_data,index=tmp_index,columns=[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pearsons correlation from the variables using PANDAS function#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corr_matrix = df_prcp\n",
    "#corr_matrix.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = np.sin(np.arange(100)/10.) + np.random.random_sample(100)\n",
    "synthetic = pd.DataFrame(data=test,columns=['vals'])\n",
    "running_test = pd.rolling_mean(synthetic[\"vals\"], window=10, min_periods=3, center = True) \n",
    "plt.plot(synthetic)\n",
    "plt.plot(running_test,'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#window_size = 2\n",
    "#for n, date in enumerate(low_risk.index[window_size - 1:]):\n",
    " #   print(date.date(), (date - low_risk.index[n -1]).days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
