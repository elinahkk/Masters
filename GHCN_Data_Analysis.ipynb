{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division,generators\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sci\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "from scipy.stats import norm as scipy_stats_norm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Read the station data downloaded from GHCN archive###\n",
    "Data obtained from http://www.ncdc.noaa.gov/cdo-web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(date_number):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the DATE of GHCN into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(date_number)\n",
    "    return pd.datetime(int(dstring[0:4]),int(dstring[4:6]),int(dstring[6:8]))\n",
    "\n",
    "def get_df(fnm, var, no_missing = True):\n",
    "    \"\"\"\n",
    "    Create a dataframe for a single station, with a time index, for a single\n",
    "    variable of data given as a key word (e.g. PRECIP, TMAX, TMIN).\n",
    "    Requires file path and name (fnm).\n",
    "    no_missing is a Bool that optionally masks out values < -99 from the df.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fnm)\n",
    "    dt_indx = [get_date(date) for date in df.DATE]\n",
    "    data_vals = df[var].values\n",
    "    if var is 'PRCP':\n",
    "        data_vals = data_vals / 10.  # This is to convert precip data to mm\n",
    "    if no_missing:\n",
    "        tmp_df = pd.DataFrame(data=data_vals,\n",
    "                              index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "        mask = tmp_df > -99.  # A catchall value for missing data in GHCN\n",
    "        return tmp_df[mask]\n",
    "    else:\n",
    "        return pd.DataFrame(data=data_vals,\n",
    "                             index=dt_indx,columns=[df.STATION[0][6:]])\n",
    "\n",
    "def get_combined_df(fpth, var):\n",
    "    \"\"\"\n",
    "    From a given file path, and variable, extract data from all .csv files, and\n",
    "    place in a single dataframe object.\n",
    "    \"\"\"\n",
    "    flist = glob.glob(fpth)\n",
    "    df_dic = {}\n",
    "    for f in flist:\n",
    "        df_dic[f[5:]] = get_df(fnm = f, var = var, no_missing=True)\n",
    "    return pd.concat([df_dic[key] for key in df_dic.keys()],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Get_combined() function to create dataframes out of all data in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_tmax = get_combined_df(fpth=\"Data/*.csv\",var=\"TMAX\")\n",
    "df_tmin = get_combined_df(fpth=\"Data/*.csv\",var=\"TMIN\")\n",
    "df_prcp = get_combined_df(fpth=\"Data/*.csv\",var=\"PRCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for station in df_prcp:\n",
    "    print(station, np.max(df_prcp[station]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot time series of precipitation for all stations, and also accumulate the data and plot the average rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of masking and accessing data from stations...\n",
    "#station = df_prcp.keys()[1]\n",
    "#plt.plot(df_prcp[station].index,df_prcp[station],'.',alpha=0.5)\n",
    "#plt.title(\"Station {0:s}\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.KE000063740[df_prcp.KE000063740 > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Time series plots###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Mean and SEM values: Mean uncertainty is given by SEM, where:\n",
    "$SEM = \\frac{\\sigma}{\\sqrt{n-1}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_SEM(data):\n",
    "    \"\"\"\n",
    "    Calculate Standard error of the mean. No nan's \n",
    "    should be in the input (numpy) array.\n",
    "    \"\"\"\n",
    "    return np.std(data)/np.sqrt(len(data) - 1)\n",
    "\n",
    "\n",
    "def gather_daily_stats(date, df):\n",
    "    \"\"\"\n",
    "    For a specified day, given by date, create a short array of \n",
    "    observed values (obs) excluding the NANs. Return the mean, \n",
    "    and SEM value.\n",
    "    Restrictions: more than one observation on a day, not a missing\n",
    "    value, less than 300 mm per day (which is erroneous).\n",
    "    \"\"\"\n",
    "    obs = np.array([df_prcp[key][day] for key in df_prcp.keys()])\n",
    "    obs = obs[(obs > -1) & (obs < 500)]\n",
    "    \n",
    "    if len(obs) < 2:\n",
    "        return np.NAN, np.NAN\n",
    "    return np.mean(obs), calc_SEM(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MAD based outlier calculation.\n",
    "#def rej_Olier(data, thresh = 0.):\n",
    "#    \"\"\"\n",
    "#    Calculate biweights of mean to reject outliers in df_prcp. No nan's \n",
    "#    should  also be in the input (numpy) array.\n",
    "#    \"\"\"\n",
    "#    diff = np.abs(data - np.median(data))\n",
    "#    mad = np.median(diff)   #median of the absolute deviation\n",
    "#    mod_obs = diff/mad if mad else 0.\n",
    "#    return data[mod_obs > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an accumulated time series (with SEM uncertainty values)\n",
    "means = []\n",
    "sems = []\n",
    "for day in df_prcp.index:\n",
    "    tmp_mean, tmp_sem = gather_daily_stats(date=day, df=df_prcp)\n",
    "    means.append(tmp_mean)\n",
    "    sems.append(tmp_sem)\n",
    "means = np.array(means)\n",
    "sems = np.array(sems)\n",
    "df_prcp['Accumulated']=pd.Series(means,index=df_prcp.index)  #adding columns to the dataframe!\n",
    "df_prcp['Acc_SEM']=pd.Series(sems,index=df_prcp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_ts = plt.figure(dpi=72)\n",
    "daily_ts.set_size_inches(15,5)      # Specify the figure size\n",
    "ax1 = daily_ts.add_subplot(111)     # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "#ax1.plot(df_prcp.index, df_prcp.Accumulated,'.g',ms=2.0)\n",
    "\n",
    "ax1.errorbar(df_prcp.index, df_prcp.Accumulated,\n",
    "             yerr=df_prcp.Acc_SEM, c='b', alpha=0.25, fmt=',')\n",
    "ax1.set_ylim(0,120)\n",
    "plt.xlim('1953-01-01','2015-12-31')\n",
    "plt.title(\"Mean East African Precipitation\")\n",
    "plt.ylabel(\"Precipitation (mm day$^{-1}$)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.grid(True)\n",
    "plt.show(daily_ts)\n",
    "#daily_ts.savefig('Daily_ts.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Density plots###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N.b. the KDE (kernel density estimate) is Gaussian - which is not true\n",
    "# for precip data (log or power law data)...\n",
    "mask = df_prcp.Accumulated > 0.0\n",
    "daily_dp = plt.figure()\n",
    "daily_dp.set_size_inches(12,5)\n",
    "ax = daily_dp.add_subplot(122)\n",
    "\n",
    "sns.distplot(df_prcp.Accumulated[mask],bins=100,norm_hist = True,kde=False,color = 'r')\n",
    "sns.kdeplot(df_prcp.Accumulated[mask],shade=True,kernel='cos',cumulative=False,color='b')\n",
    "leg1=ax.legend(['KDE','Accumulated mean'],prop={'size':11},\n",
    "                numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_xlim(0,25)\n",
    "ax.set_title(\"East Africa Mean Precipitation\")\n",
    "ax.set_xlabel(r'Precip. (mm day$^{-1}$)')\n",
    "ax.set_ylabel('Density (0-1)')\n",
    "\n",
    "plt.show(daily_dp)\n",
    "#daily_dp.savefig('Densityplot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_prcp.Accumulated[df_prcp.Accumulated>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot # Hot tip - look in SEABORN for statistical plots and help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "1. find out why the later part of the data has high variability\n",
    "2. make sure you are happy/add any logical restrictions to improve the data quality in Accumulated dataset\n",
    "3. Caclulate population statistics, histrogram, density plots (PDF, CDF), and fits to the population. Try several fit approaches, and show which is best.\n",
    "4. Use the CDF (or a percentile function) to determine the key (IQR, median, tails etc) of the population\n",
    "5. (hard) try to fit to the population. Reccomend trying a nth order polyfit using np.polyfit()\n",
    "6. Use the statistical threshold values to define 'extreme' precipitation, and work out the:\n",
    "  * frequency of extreme events,\n",
    "  * duration (lenght) of extreme events,\n",
    "  * magnitude (intensity) of extreme events\n",
    "  \n",
    "For task 6, you can plot these statistics as time dependent, or distributions, or something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(df_prcp.Accumulated[mask], bins=60)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram\n",
    "#source code from https://github.com/benlaken/Tanzania/blob/master/Precipitation_Tanzania.ipynb\n",
    "hist_dp = plt.figure()\n",
    "hist_dp.set_size_inches(5,5)          # Specify the output size\n",
    "ax1 = hist_dp.add_subplot(211)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax2 = hist_dp.add_subplot(212)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "# the histogram of the data\n",
    "ax1.set_title(r' Mean East African Precipitation')\n",
    "n, bins, patches = ax1.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled')\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel('Density')\n",
    "n, bins, patches = ax2.hist(df_prcp.Accumulated[mask], 100, normed=True, facecolor='blue', alpha=0.75,\n",
    "                            histtype='stepfilled',cumulative=True)\n",
    "plt.xlabel(r'mm day$^{-1}$')\n",
    "plt.ylabel('Cumulative density')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "#hist_dp.savefig('Density_plots.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "   # define extreme quantiles\n",
    "percentileZero    = min(df_prcp.Accumulated[mask])\n",
    "percentileHundred = max(df_prcp.Accumulated[mask])\n",
    "\n",
    "print('Min. precip', percentileZero)\n",
    "print('Max. precip', percentileHundred)\n",
    "print(\"Median\", np.percentile(df_prcp.Accumulated[mask],50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "srtd = sorted(df_prcp.Accumulated[mask])\n",
    "percent = [val/len(srtd) * 100. for val in range(len(srtd))]\n",
    "plt.plot(percent,srtd)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.percentile(df_prcp.Accumulated[mask],90))\n",
    "print(np.percentile(srtd,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. Seasonality###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the DOY mean over the data-period (climatology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doy_mean=[]\n",
    "doy_sem =[]\n",
    "\n",
    "for doy in range(366):\n",
    "    index = df_prcp.index.dayofyear == doy+1 \n",
    "    #print(index)\n",
    "    doy_mean.append(np.nanmean(df_prcp['Accumulated'][index]))\n",
    "    doy_sem.append(calc_SEM(df_prcp['Accumulated'][index]))\n",
    "\n",
    "doy_mean = np.array(doy_mean)\n",
    "doy_sem = np.array(doy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssn_rmean = pd.rolling_mean(doy_mean, window=30, min_periods=0, center = True)\n",
    "#ssn_rmean[-30:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the seasonal climatology East Africa precip data\n",
    "mnths= ['Jan','Feb','Mar','Apr','May','June','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "#mrange = arange(12)\n",
    "\n",
    "my_sclim = plt.figure(dpi=72)\n",
    "my_sclim.set_size_inches(10,5)        # Specify the output size\n",
    "ax1 = my_sclim.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, c='b', alpha=0.8)\n",
    "ax1.plot(range(366), ssn_rmean,'r-')\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"East Africa DOY Mean ($\\mu$) Rainfall (& 30day smooth)\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.grid(True)  \n",
    "#my_sclim.savefig('My_SeasonalClimatology_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly\n",
    "  * Use the seasonal DOY mean to calculate deviations (anomaly) from the daily mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wordy example of how to access/calculate anomaly\n",
    "for daily_rain in zip(df_prcp.index[5000:5003],df_prcp.Accumulated[5000:5003]):\n",
    "    print('Day {0}, rainfall {1:3.2f}mm'.format(daily_rain[0].date(),daily_rain[1]))\n",
    "    print('DOY is',daily_rain[0].dayofyear)\n",
    "    print(\"DOY climo value is {0:3.2f}\".format(doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(\"Daily anomaly is {0:3.2f}\".format(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1]))\n",
    "    print(np.isnan(daily_rain[1]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Create a seasonal deviation from climatology--\n",
    "#Anomalies = Observation - Climatology\n",
    "prcp_anom = []\n",
    "for daily_rain in zip(df_prcp.index,df_prcp.Accumulated):\n",
    "    if np.isnan(daily_rain[1]):\n",
    "        prcp_anom.append(np.NAN)\n",
    "    else:\n",
    "        prcp_anom.append(daily_rain[1] - doy_mean[daily_rain[0].dayofyear -1])\n",
    "prcp_anom = np.array(prcp_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prcp['Acc_anomaly'] = prcp_anom  #adding columns to the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_prcp.index[prcp_anom > -999.],prcp_anom[prcp_anom > -999.],alpha=0.5)\n",
    "#df_prcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---plot the anomalized rainfall data with errors---\n",
    "my_anom = plt.figure(dpi=72)\n",
    "my_anom.set_size_inches(15,6)        # Specify the output size\n",
    "ax1 = my_anom.add_subplot(111)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "ax1.errorbar(df_prcp['Acc_anomaly'].index,df_prcp['Acc_anomaly'],yerr=df_prcp['Acc_SEM'],\n",
    "             color='b', fmt='.',xerr=None,alpha=0.5)\n",
    "ax1.set_ylim(-10,100)\n",
    "plt.xlim('1953-01-01','2013-12-31')\n",
    "ax1.set_title(r'Deseasonalized Precipitation ($\\delta$Precip.)')\n",
    "ax1.set_ylabel(r'Anomalized Precip')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "\n",
    "#plt.legend(framealpha=0.9)\n",
    "plt.show(my_anom)\n",
    "#my_anom.savefig('EA anomalized.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doy_values = [doy.dayofyear - 1 for doy in df_prcp.index]\n",
    "figx = plt.figure(dpi=72)\n",
    "figx.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = figx.add_subplot(111)   \n",
    "\n",
    "#---Plot the seasonal climatology East Africa precip data---\n",
    "ax1.errorbar(range(366),doy_mean,xerr=None, yerr=doy_sem, color='b', alpha=0.8 )\n",
    "ax1.plot(df_prcp.index.dayofyear -1 ,df_prcp['Accumulated'],'.',ms=2.5,alpha=1.0,color='r')\n",
    "plt.xlim(0,max(range(366)))\n",
    "plt.title(\"\")\n",
    "plt.ylabel(\"Precipitation (mm)\")\n",
    "plt.xlabel(\"Day of Year (DOY)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. Extreme Precip Events ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extreme events have been defined  by absolute threshhold set by SWFDP-RSMC-Nairobi###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A mask for the df_prcp to identify categories of Extreme rainfall events\n",
    "\"\"\"\n",
    "The thresholds used in here are based on the definitions as used\n",
    "by SWFDP-EA. It should be noted that this hold under natural conditions\n",
    "\"\"\"\n",
    "high_risk = df_prcp.Accumulated[df_prcp.Accumulated > 50]\n",
    "medium_risk = df_prcp.Accumulated[(df_prcp.Accumulated > 20) & (df_prcp.Accumulated < 50)]\n",
    "low_risk = df_prcp.Accumulated[(df_prcp.Accumulated > 5) & (df_prcp.Accumulated < 20)]\n",
    "no_risk = df_prcp.Accumulated[df_prcp.Accumulated < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_floodrisk = plt.figure(dpi=72)\n",
    "daily_floodrisk.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = daily_floodrisk.add_subplot(111)     #\n",
    "\n",
    "ax1.plot(high_risk.index, high_risk,'ro',alpha=1.,ms=2)\n",
    "ax1.plot(medium_risk.index, medium_risk,'bo',alpha=0.9,ms=2)\n",
    "ax1.plot(low_risk.index, low_risk,'co',alpha=0.9,ms=2)\n",
    "ax1.plot(no_risk.index, no_risk,'go',alpha=0.9,ms=2)\n",
    "leg1=ax1.legend(['high risk','medium risk','low risk','no risk'],\n",
    "                prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "#plt.xlim('1950-01-01','2015-12-31')\n",
    "plt.title(r\"Mean East African Precipitation\")\n",
    "plt.ylabel(r\"Precipitation (mm day$^{-1}$)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.grid(True)\n",
    "plt.show(daily_floodrisk)\n",
    "\n",
    "#daily_ts.savefig('Daily_floodrisk.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Summary statistics####\n",
    "######Frequency of extreme events based on absolute threshhold set by SWFDP-RSMC-Nairobi######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_risk.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#low_risk.groupby( [low_risk.index.year, low_risk.index.month, low_risk.index.day] ).count()\n",
    "lwrisk_freq = low_risk.groupby( [low_risk.index.year] ).count()\n",
    "mdrisk_freq = medium_risk.groupby( [medium_risk.index.year] ).count()\n",
    "hgrisk_freq = high_risk.groupby( [high_risk.index.year] ).count()\n",
    "print(hgrisk_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frq_rmean_low = pd.rolling_mean(lwrisk_freq, window=10, min_periods=0, center = True)\n",
    "frq_rmean_med = pd.rolling_mean(mdrisk_freq, window=10, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency plot \n",
    "freq = plt.figure(dpi=72)\n",
    "freq.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = freq.add_subplot(121)\n",
    "ax2 = freq.add_subplot(122)\n",
    "\n",
    "ax1.plot(lwrisk_freq.index, lwrisk_freq ,'b-',ms=3.0,alpha=1.)\n",
    "ax1.set_title('Integer count of Low risk extreme precip based \\n on absolute threshhold by SWFDP-RSMC-Nairobi')\n",
    "ax1.plot(lwrisk_freq.index, frq_rmean_low,'r--')\n",
    "ax1.set_ylabel(r'Number of low risk events (counts)')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(mdrisk_freq.index, mdrisk_freq ,'b-',ms=3.0,alpha=1.)\n",
    "ax2.plot(mdrisk_freq.index, frq_rmean_med,'r--')\n",
    "ax2.set_title(' Integer count of Medium risk extreme precip based \\n on absolute threshhold by SWFDP-RSMC-Nairobi')\n",
    "ax2.set_xlabel(r\"Years\")\n",
    "ax2.set_ylabel('Number of medium risk events (counts)')\n",
    "ax2.grid(True)\n",
    "#freq.savefig('freq_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Duration of extreme events####\n",
    "Here I calculate the time between heavy precipitation (risk) from the observed time directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_risk.index[2], low_risk.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = low_risk.index[2] - low_risk.index[1]\n",
    "print(\"diffrence in days between first and second lowrisk:\",test.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowrisk_times = 1\n",
    "for n, date in enumerate(low_risk.index[lowrisk_times - 1:3]):\n",
    "    print(date.date(), (date - low_risk.index[n -1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Duration\n",
    "lowrisk_dur = []\n",
    "mediumrisk_dur = []\n",
    "risk_time = 1\n",
    "for n, date in enumerate(low_risk.index[risk_time - 1:]):\n",
    "    lowrisk_d = (date - low_risk.index[n -1]).days\n",
    "    \n",
    "    lowrisk_dur.append(lowrisk_d)\n",
    "    \n",
    "lowrisk_dur=np.array(lowrisk_dur)    \n",
    "for n, date in enumerate(medium_risk.index[risk_time - 1:]):    \n",
    "    mediumrisk_d = (date - medium_risk.index[n -1]).days\n",
    "    \n",
    "    mediumrisk_dur.append(mediumrisk_d)\n",
    "    \n",
    "mediumrisk_dur=np.array(mediumrisk_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowrisk_dur[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medium_risk.index[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(medium_risk.index, mediumrisk_dur, width=1.,alpha=1.) \n",
    "plt.xlim('1953-01-03','1990-12-31')\n",
    "plt.ylim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Duration plot \n",
    "freq = plt.figure(dpi=72)\n",
    "freq.set_size_inches(20,5)        # Specify the output size\n",
    "ax1 = freq.add_subplot(121)\n",
    "ax2 = freq.add_subplot(122)\n",
    "\n",
    "ax1.plot(low_risk.index, lowrisk_dur ,'b-',ms=3.0,alpha=1.)\n",
    "ax1.set_title('Duration of consecutive Low risk precip events based \\n on absolute threshhold by SWFDP-RSMC-Nairobi')\n",
    "ax1.set_ylabel(r'Days between low risk events')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.set_xlim('1953-01-03','1990-12-31')\n",
    "ax1.set_ylim(0,100)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(medium_risk.index, mediumrisk_dur,'b-',ms=3.0,alpha=1.)\n",
    "ax2.set_title(' Duration of consecutive Medium risk precip based \\n on absolute threshhold by SWFDP-RSMC-Nairobi')\n",
    "ax2.set_ylabel('Days between low risk events')\n",
    "ax2.set_ylim(0,700)\n",
    "ax2.set_xlabel(r\"Years\")\n",
    "ax2.set_xlim('1953-01-03','1990-12-31')\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme events based on statistical values of daily anomalies and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],90)\n",
    "drought_threshold = np.percentile(df_prcp['Acc_anomaly'][mask],10)\n",
    "\n",
    "print('90th percentile = ',flood_threshold)\n",
    "print('10th percentile = ',drought_threshold)\n",
    "print('50th percentile = ',np.percentile(df_prcp['Acc_anomaly'][mask],50))\n",
    "#sns.distplot(df_prcp['Acc_anomaly'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dist = plt.figure()\n",
    "my_dist.set_size_inches(15,5)               # Specify the output size\n",
    "ax1 = my_dist.add_subplot(121)              # Add an axis frame object to the plot (i.e. a pannel)\n",
    "\n",
    "#Univeriate distribution of Observed daily precipitation.\n",
    "sns.distplot(df_prcp['Acc_anomaly'][mask],bins=100, norm_hist=True, kde=False) # Filled bars  \n",
    "sns.kdeplot(df_prcp['Acc_anomaly'][mask],shade=False,kernel='gau',cumulative=False,color='r',lw=1.5)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],90), 0.00, 0.2, colors='b',linestyle='--',lw=1.0)\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],50), 0.00, 0.2, colors='b',lw=1.0) #Marker line of Median\n",
    "ax1.vlines(np.percentile(df_prcp['Acc_anomaly'][mask],10), 0.00, 0.2, colors='b',linestyle='-.',lw=1.0)\n",
    "leg1=ax1.legend(['KDE','90th percentile','50th percentile','10th percentile','observed anomalies'],\n",
    "                prop={'size':11},numpoints=1,markerscale=5.,frameon=True,fancybox=True)\n",
    "\n",
    "ax1.grid(True)\n",
    "ax1.set_ylabel(r'Density',fontsize=11)\n",
    "ax1.set_xlabel('Accumulated precip. anomaly (mm)',fontsize=11)\n",
    "ax1.set_xlim(-10, 40)\n",
    "ax1.set_ylim(0.00, 0.2)\n",
    "\n",
    "\n",
    "plt.show(my_dist)\n",
    "#daily_ts.savefig('Daily_ts.pdf',dpi=300)\n",
    "\n",
    "#my_dist.savefig(\"EA_Normalized_Percentile.pdf\",dpi=300,transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mask for the df_prcp to identify the extreme dates (flood and drought)\n",
    "extremes = ((df_prcp['Acc_anomaly'] > flood_threshold) | (df_prcp['Acc_anomaly'] < drought_threshold))\n",
    "flood = (df_prcp['Acc_anomaly'] > flood_threshold)\n",
    "drought = (df_prcp['Acc_anomaly'] < drought_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_threshold = plt.figure(dpi=72)\n",
    "fig_threshold.set_size_inches(10,5)      # Specify the figure size\n",
    "ax1 = fig_threshold.add_subplot(111)   \n",
    "ax1.scatter(df_prcp['Acc_anomaly'][mask].index, df_prcp['Acc_anomaly'][mask],\n",
    "            alpha=0.1, marker='.')\n",
    "ax1.scatter(df_prcp['Acc_anomaly'][extremes].index, df_prcp['Acc_anomaly'][extremes],\n",
    "            alpha=0.3, marker='.', color='r')\n",
    "plt.title(\"Extreme rainfall based on threshold value detection\")\n",
    "plt.ylabel(\"Precipitation anomaly (mm)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.xlim('1953-01-01','1970-12-31')\n",
    "ax1.grid(True)\n",
    "#fig_threshold.savefig('Extreme_Threshhold_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Summary statistics####\n",
    "####Intensity, Duration and Frequency of extreme events based on defined statistical extreme threshold####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can use groupby to querey your dataset \n",
    "#pd.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or you can write hacks like this, to pull out data based on the index\n",
    "#---Splitting the data into groups based on extreme threshhold\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    wet_extreme = df_prcp[\"Acc_anomaly\"][flood][df_prcp[\"Acc_anomaly\"][flood].index.year == year]\n",
    "    dry_extreme = df_prcp[\"Acc_anomaly\"][drought][df_prcp[\"Acc_anomaly\"][drought].index.year == year]\n",
    "    \n",
    "    print(year,len(wet_extreme), year,len(dry_extreme))\n",
    "    break \n",
    "# eitherway, do statistics on the frequency, intensity, and duration of flood and drought events\n",
    "# e.g. a time-series. More distributions, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flood_freq = []\n",
    "drought_freq = []\n",
    "yr_day_count = []\n",
    "years = []\n",
    "flood_mean=[]\n",
    "flood_sem =[]\n",
    "drought_mean=[]\n",
    "drought_sem =[]\n",
    "\n",
    "for year in range(min(df_prcp.index.year),max(df_prcp.index.year)):\n",
    "    tmp_yr_data = df_prcp[\"Acc_anomaly\"][df_prcp.index.year == year]  # pool data for each year\n",
    "    #print(tmp_yr_data)\n",
    "    yr_day_count.append(tmp_yr_data.count())\n",
    "    years.append(year)\n",
    "    if tmp_yr_data.count() > 1:\n",
    "        flood_freq.append(len(tmp_yr_data[flood]))\n",
    "        #print(len(tmp_yr_data[flood]))\n",
    "        drought_freq.append(len(tmp_yr_data[drought]))\n",
    "        flood_mean.append(np.nanmean(tmp_yr_data[flood]))\n",
    "        flood_sem.append(calc_SEM(tmp_yr_data[flood]))\n",
    "        drought_mean.append(np.nanmean(tmp_yr_data[drought]))\n",
    "        drought_sem.append(calc_SEM(tmp_yr_data[drought]))\n",
    "    else:\n",
    "        flood_freq.append(np.NAN)\n",
    "        drought_freq.append(np.NAN)\n",
    "     \n",
    "        flood_mean.append(np.NAN)\n",
    "        flood_sem.append(np.NAN)\n",
    "        drought_mean.append(np.NAN)\n",
    "        drought_sem.append(np.NAN)\n",
    "        \n",
    "    \n",
    "flood_freq = np.array(flood_freq)\n",
    "drought_freq = np.array(drought_freq)\n",
    "yr_day_count = np.array(yr_day_count)\n",
    "years = np.array(years)\n",
    "flood_mean = np.array(flood_mean)\n",
    "flood_sem = np.array(flood_sem)\n",
    "drought_mean = np.array(drought_mean)\n",
    "drought_sem = np.array(drought_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running_test = pd.rolling_mean(synthetic[\"vals\"], window=10, min_periods=3, center = True) \n",
    "int_rmean = pd.rolling_mean(flood_mean[yr_day_count > 350], window=3, min_periods=0, center = True)\n",
    "int_drmean = pd.rolling_mean(drought_mean[yr_day_count > 350], window=3, min_periods=0, center = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Intensity of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Intensity\n",
    "my_int = plt.figure(dpi=72)\n",
    "my_int.set_size_inches(15,5)        # Specify the output size\n",
    "ax1 = my_int.add_subplot(121)\n",
    "ax2 = my_int.add_subplot(122)\n",
    "\n",
    "ax1.errorbar(years[yr_day_count > 350],flood_mean[yr_day_count > 350],  #Masking missing values\n",
    "             xerr=None, yerr=flood_sem[yr_day_count > 350],color='b', fmt='.', alpha=1.)\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], int_rmean,'g--')\n",
    "#ax1.plot(years[yr_day_count > 350], int_trend,'b-')\n",
    "ax1.set_title('Mean ($\\mu$) intensity of flood events in East Africa\\n based on threshold value detection')\n",
    "ax1.set_ylabel(r'Intensity')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.errorbar(years[yr_day_count > 350],drought_mean[yr_day_count > 350],\n",
    "             xerr=None, yerr=drought_sem[yr_day_count > 350], color='r', fmt='.', alpha=1.)\n",
    "ax2.plot(years[yr_day_count > 350], int_drmean,'g--')\n",
    "ax2.set_title(' Mean ($\\mu$)intensity of drought events in East Africa\\n based on threshold value detection ')\n",
    "ax2.set_xlabel(r\"Years\")\n",
    "ax2.set_ylabel('Intensity')\n",
    "ax2.grid(True)\n",
    "#my_int.savefig('My_intensity_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = np.polyfit(years[yr_day_count > 350], flood_mean[yr_day_count > 350], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##calc the trendline (linear fitting)\n",
    "trend = np.polyfit(flood_freq[yr_day_count > 350], years[yr_day_count > 350], len(flood_freq[yr_day_count > 350]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##calc the trendline (linear fitting)\n",
    "#from scipy.interpolate import spline\n",
    "#for year in range(min(df_prcp.index.year),max(df_prcp.index.year))\n",
    "#flood_freq_smooth = np.linspace9(min(flood_freq[yr_day_count > 350], \n",
    "        #                        max(flood_freq[yr_day_count > 350]) for for n, \n",
    "       #                         date in enumerate(tmp_yr_data.index[flood_freq], 10)\n",
    "#drought_freq_smooth = np.linspace(drought_freq.min(), drought_freq.max(), 10)\n",
    "#years_smooth = spline(flood_freq[yr_day_count > 350], years[yr_day_count > 350], \n",
    "                      #flood_freq_smooth)\n",
    "#plt.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350], 'b.', alpha=0.8)\n",
    "#plt.plot(years_smooth, flood_freq_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.timedelta_range(start=None, end=None, periods=None, freq='D', name=None, closed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Frequency of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency \n",
    "my_ = plt.figure(dpi=72)\n",
    "my_.set_size_inches(15,5)        # Specify the output size\n",
    "ax = my_.add_subplot(121)        # Add an axis frame object to the plot (i.e. a pannel)\n",
    "ax1 = my_.add_subplot(122) \n",
    "\n",
    "\n",
    "ax.plot(years[yr_day_count > 350],flood_freq[yr_day_count > 350], 'b.', alpha=0.8)\n",
    "ax.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350], 'r.',alpha=0.8)\n",
    "leg=ax.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_title('Integer count of Extreme precip events\\n based on threshold value detection')\n",
    "ax.set_ylabel(r'Number of Extreme events (counts)')\n",
    "ax.set_xlabel('Years')\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "ax1.plot(years[yr_day_count > 350], flood_freq[yr_day_count > 350]/\n",
    "        yr_day_count[yr_day_count > 350], 'b.', alpha=1.)\n",
    "ax1.plot(years[yr_day_count > 350],drought_freq[yr_day_count > 350]/\n",
    "        yr_day_count[yr_day_count > 350],'r.', alpha=1.)\n",
    "leg=ax1.legend(['Floods','Drought',],prop={'size':10},numpoints=1,markerscale=1.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_title('Extreme precip events\\n based on threshold value detection')\n",
    "ax1.set_ylabel(r'Number of Extreme events (counts)')\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.show(my_)\n",
    "#my_.savefig('My_Frequency_plot.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Duration of extreme rainfall  events based on defined statistical extreme threshold######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration\n",
    "  * If you want to look/do operations on time diffrences, this is called timedelta in the Pandas / datetime packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = tmp_yr_data[drought].index[1] - tmp_yr_data[drought].index[0]\n",
    "print(\"diffrence in days between first and second flood:\",test.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_days_since(df, truth_array, name_to_add):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe (df) as input, and a truth array\n",
    "    related to that dataframe (e.g. df=df_prcp, truth_array=drought)\n",
    "    and will then go through each date in the dataframe, look if the\n",
    "    truth value is True, and if it is, it will see how long since the\n",
    "    last truth value occured, and give an integer value (for day count)\n",
    "    which is then placed in an array, and appended to the original\n",
    "    dataframe at the end, with the name_to_add as the column name.\n",
    "    \"\"\"\n",
    "    days_since_list = []\n",
    "    last_day = df.index[0]  # Initilise the state of the 'last' day\n",
    "    for day in df.index:\n",
    "        if truth_array[day] == True:\n",
    "            days_since = day - last_day\n",
    "            days_since = int(days_since.days)\n",
    "            last_day = day  # update the state of last day to current true day\n",
    "            if days_since > 1000: # Just check the values aren't silly\n",
    "                days_since = np.NAN\n",
    "        else:\n",
    "            days_since = np.NAN\n",
    "        days_since_list.append(days_since)\n",
    "    days_since_list = np.array(days_since_list)\n",
    "    df[name_to_add]=days_since_list #adding column to the df_prcp data frame\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_prcp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_days_since(df=df_prcp, truth_array=drought, name_to_add = 'DS_Last_D')#Days  since last drought\n",
    "add_days_since(df=df_prcp, truth_array=flood, name_to_add = 'DS_Last_F') #Days since last flood\n",
    "#add_days_since(df=df_prcp, truth_array=low_risk, name_to_add = 'DS_Last_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_duration = plt.figure()\n",
    "my_duration.set_size_inches(10,5)        \n",
    "ax1 = my_duration.add_subplot(111)\n",
    "#ax2 = my_duration.add_subplot(122) \n",
    "\n",
    "ax1.plot(df_prcp.DS_Last_F.index, df_prcp.DS_Last_F,'-b',ms=3.0,alpha=0.75)\n",
    "ax1.plot(df_prcp.DS_Last_D.index, df_prcp.DS_Last_D,'-r',ms=3.0,alpha=1.0)\n",
    "\n",
    "#ax1.bar(df_prcp.DS_Last_F.index, df_prcp.DS_Last_F, width=0.8, color = 'b')\n",
    "#ax1.bar(df_prcp.DS_Last_D.index, df_prcp.DS_Last_D, width=0.8, color = 'r')\n",
    "leg=ax1.legend(['DS_Last_F','DS_Last_D',],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "\n",
    "ax1.set_ylabel(r'Duration since last event (Days) ')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_title(r'Duration between extreme events')\n",
    "ax1.set_ylim(0, 150)\n",
    "ax1.set_xlim('1953-01-01','1990-12-31')\n",
    "ax1.grid(True)\n",
    "plt.show(my_duration)\n",
    "#my_duration.savefig('my_duration_curve.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(df_prcp.DS_Last_F.index,df_prcp.DS_Last_F,width=0.8,alpha=1.,color='b',label='Days Since last Flood')\n",
    "plt.bar(df_prcp.DS_Last_D.index,df_prcp.DS_Last_D,width=0.8,alpha=1.,color='r',label='Days since last Drought')\n",
    "plt.ylim(0,150)\n",
    "plt.xlim('1953-01-01','1990-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(np.polyfit(df_prcp.DS_Last_F, df_prcp.DS_Last_F.index, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extreme event based on cumulative statistical values (boxcar approach)###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Type of boxcar function\n",
    "\"\"\"\n",
    "Interested in the sum of mean precip for current day plus the next 2 days\n",
    "If the sum is greater than 100mm, then this could be a signal\n",
    "for potential medium-high risk for flood, low risk if greater than 50mm but\n",
    "less than 100. \n",
    "\"\"\"\n",
    "running_total = pd.rolling_sum(df_prcp[\"Accumulated\"], window=3, min_periods=3, center = True) #inverse=[::-1]\n",
    "print(np.max(running_total), np.max(df_prcp[\"Accumulated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(running_total[7000:7005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_total = plt.figure()\n",
    "my_total.set_size_inches(10,5)        # Specify the output size\n",
    "ax1 = my_total.add_subplot(111)\n",
    "\n",
    "ax1.plot(running_total.index, running_total,'.g',ms=3.0,alpha=0.75)\n",
    "ax1.plot(running_total[running_total > 50].index, running_total[running_total > 50],'.r',ms=3.0,alpha=1.0)\n",
    "leg=ax1.legend(['No risk','flood risk',],prop={'size':10},numpoints=1,markerscale=5.,\n",
    "                frameon=True,fancybox=True)\n",
    "ax1.set_ylabel(r'Precipitation (mm day$^{-1}$)')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_title(r'Running sum for Mean precipitation in East Africa')\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.grid(True)\n",
    "plt.show(my_total)\n",
    "#my_total.savefig('total_ts.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Summary statistics####\n",
    "######Frequency of flood risk events based on cumulative statistical values (boxcar approach)######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flood_risk = running_total[running_total > 50] \n",
    "#print(flood_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "floodrisk_freq = flood_risk.groupby( [flood_risk.index.year] ).count()\n",
    "print(floodrisk_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Frequency plot \n",
    "flood_freq = plt.figure(dpi=72)\n",
    "flood_freq.set_size_inches(15,3)        #output size\n",
    "ax1 = flood_freq.add_subplot(121)\n",
    "\n",
    "ax1.plot(floodrisk_freq.index, floodrisk_freq ,'r.',ms=7.0,alpha=1.)\n",
    "ax1.set_title('Integer count of flood risk events based on\\n cumulative statistical values (boxcar approach)')\n",
    "#ax1.plot(floodrisk_freq.index, frq_rmean_low,'r--')\n",
    "ax1.set_ylabel(r'Number of events (counts)')\n",
    "ax1.set_xlabel(r'Year')\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim(0,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Duration of flood risk events based on cumulative statistical values (boxcar approach)######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####From the Frequency of occurance its evident that duration between flood events takes upto 22 years (1967-1989)### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Correlation Analysis###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_index(dt):\n",
    "    \"\"\"\n",
    "    Turn the int64 value from the YR, MON of indices into a pd.datetime\n",
    "    \"\"\"\n",
    "    dstring = str(dt)\n",
    "    return pd.datetime((int(dstring[0:4]),int(dstring[4:6]))) #year Month\n",
    "                       \n",
    "def corr_df(fpath, label, clim_index):\n",
    "    print(fpath)\n",
    "    for file in glob.glob(fpath):\n",
    "        data_in = pd.read_csv(file)\n",
    "        \n",
    "        data = []\n",
    "        dates = [date_index(entry) for entry in corr_df.index]\n",
    "        for month in range(12,):\n",
    "                dates.append(corr_df(corr_df.Year[entry]).month())\n",
    "                data.append(data_in)\n",
    "    return pd.DataFrame(data=data, column=[label], index=dates)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enso_path = 'ftp://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/ersst3b.nino.mth.81-10.ascii'\n",
    "#enso_data = pd.read_fwf(enso_path)\n",
    "#enso_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Fetching data from web source using Pandas######\n",
    "\n",
    "[IOD data](http://stateoftheocean.osmc.noaa.gov/sur/ind/dmi.php),  \n",
    "[ENSO data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/ersst3b.nino.mth.81-10.ascii),   \n",
    "[SOI data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/soi),   \n",
    "[QBO30mb data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/qbo.u30.index),   \n",
    "[QBO50mb data](http://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/qbo.u50.index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is aimed at finding the relationship between extreme weather events \n",
    "in EA and climate indices(ENSO, QBO, IOD), Also what is the correlation  \n",
    "between the data (and their statistical significance)?\n",
    "\"\"\"\n",
    "#iod=pd.read_fwf(\"Data/dmi.nc\")\n",
    "enso=pd.read_fwf(\"Data/noaa_mei.txt\")\n",
    "soi = pd.read_fwf(\"Data/noaa_soi.txt\")\n",
    "qbo30 =pd.read_fwf(\"Data/noaa_qbo30.txt\")\n",
    "qbo50 = pd.read_fwf(\"Data/noaa_qbo50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qbo50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_index = []\n",
    "tmp_data = []\n",
    "for entry in nino.index:\n",
    "    for month in range(12,):\n",
    "            tmp_index.append(pd.datetime(nino.year[entry]).month())\n",
    "            tmp_data.append(entry)\n",
    "tmp_index = np.array(tmp_index)\n",
    "tmp_data = np.array(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = Dataset(\"Data/dmi.nc\") # Assign the netcdf file\n",
    "print(f.variables)                # Show what is in the netcdf file\n",
    "dmi = f[\"DMI\"][:]          # Call the DMI and dates and assign them to a variable \n",
    "dmi_dates = f[\"WEDCEN2\"][:]\n",
    "f.close()                   # close the connection to the netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dmi_dates, dmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split_df = nino['yr, MON,  NINO3.4, ANOM'].apply(lambda x: pd.Series(x.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Pearsons correlation from the variables using PANDAS function#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Relationship between monthly climate indices anom. & extreme precips#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corr_matrix = df_prcp\n",
    "#corr_matrix.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = np.sin(np.arange(100)/10.) + np.random.random_sample(100)\n",
    "synthetic = pd.DataFrame(data=test,columns=['vals'])\n",
    "running_test = pd.rolling_mean(synthetic[\"vals\"], window=10, min_periods=3, center = True) \n",
    "plt.plot(synthetic)\n",
    "plt.plot(running_test,'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#window_size = 2\n",
    "#for n, date in enumerate(low_risk.index[window_size - 1:]):\n",
    " #   print(date.date(), (date - low_risk.index[n -1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_prcp['Accumulated'][(mask) & (df_prcp['Accumulated'] > 25)].index, \n",
    "         #df_prcp['Accumulated'][(mask) & (df_prcp['Accumulated'] > 25)], 'bd', alpha=.5, ms=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from netCDF4 import Dataset, num2date\n",
    "#from astropy.io import ascii"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
